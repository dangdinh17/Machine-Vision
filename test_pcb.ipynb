{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/u9564043/.local/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "import shutil\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.nn.parallel import DataParallel\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "import torch.nn.functional as F\n",
    "from torchvision.utils import save_image\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from models import *\n",
    "from utils import *\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_quality = [40]\n",
    "num_imgs = 0\n",
    "mode = 1\n",
    "if mode == 0:\n",
    "    quality_subs =   ['ISR', 'IQE','ISR + IQE', 'IQE + ISR', 'IQE + ISR + IQE', 'e2e']\n",
    "    detect_subs = ['','_ISR','_IQE', '_ISR + IQE', '_IQE + ISR', '_IQE + ISR + IQE', '_e2e', 'full']\n",
    "elif mode == 1:\n",
    "    quality_subs = ['IQE','ISR + IQE', 'IQE + ISR', 'IQE + ISR + IQE', 'SRQE', 'e2e']\n",
    "    detect_subs = ['_IQE', '_ISR + IQE', '_IQE + ISR', '_IQE + ISR + IQE', '_SRQE','_e2e']\n",
    "elif mode == 2:\n",
    "    quality_subs = ['IQE','ISR + IQE', 'IQE + ISR', 'IQE + ISR + IQE']\n",
    "    detect_subs = ['_IQE', '_ISR + IQE', '_IQE + ISR', '_IQE + ISR + IQE']\n",
    "elif mode == 3:\n",
    "    quality_subs =  ['ISR', 'IQE','ISR + IQE', 'IQE + ISR', 'IQE + ISR + IQE']\n",
    "    detect_subs = ['_ISR','_IQE', '_ISR + IQE', '_IQE + ISR', '_IQE + ISR + IQE']\n",
    "elif mode == 4:\n",
    "    quality_subs =  ['IQE']\n",
    "    detect_subs = ['_IQE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_dir = '/work/u9564043/Machine-Vision/dataset/PCB_dataset/test/images'\n",
    "# psnr_dict = {\n",
    "#             \"mouse_bite\" :[],\n",
    "#             \"spur_\":[], \n",
    "#             \"missing_hole\":[],\n",
    "#             \"short\":[],\n",
    "#             \"open_circuit\":[],\n",
    "#             \"spurious_copper\":[]\n",
    "    \n",
    "#     }\n",
    "\n",
    "# hr_img_path = f'output/test_600/images'\n",
    "# hr_label_path = f'output/test_600/labels'\n",
    "\n",
    "# os.makedirs(hr_img_path, exist_ok = True)\n",
    "# os.makedirs(hr_label_path, exist_ok = True)\n",
    "\n",
    "# max_per_label = num_imgs\n",
    "# label_counter = {k: 0 for k in psnr_dict.keys()}\n",
    "# # os.makedirs(output, exist_ok = True)\n",
    "# for path in tqdm(os.listdir(img_dir), unit = 'img'):\n",
    "#     label = None\n",
    "#     for key in psnr_dict.keys():\n",
    "#         if key in path:  # Nếu tên file chứa tên nhãn\n",
    "#             label = key\n",
    "#             break\n",
    "#     if label is None:\n",
    "#         continue  # Bỏ qua nếu không xác định được nhãn\n",
    "\n",
    "#     # --- Giới hạn tối đa 100 ảnh mỗi nhãn ---\n",
    "#     if num_imgs != 0:\n",
    "#         if label_counter[label] >= max_per_label:\n",
    "#             continue\n",
    "#         label_counter[label] += 1\n",
    "    \n",
    "#     source_file = os.path.join(img_dir, path)\n",
    "#     file1 = os.path.join(hr_img_path, path)\n",
    "#     shutil.copy(source_file, file1)\n",
    "\n",
    "# source_dir = f'/work/u9564043/Machine-Vision/dataset/PCB_dataset/test/labels'\n",
    "# # Tạo thư mục đích nếu chưa tồn tại\n",
    "\n",
    "# # Sao chép các file từ thư mục nguồn sang thư mục đích\n",
    "# for filename in tqdm(os.listdir(source_dir)):\n",
    "#     source_file = os.path.join(source_dir, filename)\n",
    "#     file2 = os.path.join(hr_label_path, filename)\n",
    "#     shutil.copy(source_file, file2)\n",
    "# print(\"Đã sao chép các file thành công.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_dir = hr_img_path\n",
    "# psnr_dict = {\n",
    "#             \"mouse_bite\" :[],\n",
    "#             \"spur_\":[], \n",
    "#             \"missing_hole\":[],\n",
    "#             \"short\":[],\n",
    "#             \"open_circuit\":[],\n",
    "#             \"spurious_copper\":[]\n",
    "    \n",
    "#     }\n",
    "# ssim_dict = {\n",
    "#         \"mouse_bite\" :[],\n",
    "#         \"spur_\":[], \n",
    "#         \"missing_hole\":[],\n",
    "#         \"short\":[],\n",
    "#         \"open_circuit\":[],\n",
    "#         \"spurious_copper\":[]\n",
    "\n",
    "#     }\n",
    "\n",
    "\n",
    "# # for quality in [10, 20, 30, 40, 80]:\n",
    "# for quality in test_quality:\n",
    "#     types = f'test_{quality}'\n",
    "#     # output = f'compress/quality_compress_{quality}'\n",
    "#     output_lr_img = f'output/{types}_150/images'\n",
    "#     output_hr_img = f'output/{types}_600/images'\n",
    "#     output_lr_label = f'output/{types}_150/labels'\n",
    "#     output_hr_label = f'output/{types}_600/labels'\n",
    "    \n",
    "#     os.makedirs(output_lr_img, exist_ok = True)\n",
    "#     os.makedirs(output_hr_img, exist_ok = True)\n",
    "#     os.makedirs(output_lr_label, exist_ok = True)\n",
    "#     os.makedirs(output_hr_label, exist_ok = True)\n",
    "\n",
    "#     max_per_label = 100\n",
    "#     label_counter = {k: 0 for k in psnr_dict.keys()}\n",
    "#     # os.makedirs(output, exist_ok = True)\n",
    "#     for path in tqdm(os.listdir(img_dir), desc = f'quality {quality}', unit = 'img'):\n",
    "        \n",
    "#         img_path = os.path.join(img_dir, path)\n",
    "#         # out_path = os.path.join(output, f\"{os.path.splitext(path)[0]}.png\")\n",
    "#         out_lr_path = os.path.join(output_lr_img, f\"{os.path.splitext(path)[0]}.png\")\n",
    "#         out_hr_path = os.path.join(output_hr_img, f\"{os.path.splitext(path)[0]}.png\")\n",
    "#         img = Image.open(img_path)\n",
    "#         img = img.resize((608, 608))\n",
    "#         w, h = img.size\n",
    "#         # print(h, w)\n",
    "#         out = img.resize((w//4, h//4))\n",
    "#         # out = img\n",
    "#         if quality == 'origin':\n",
    "#             out.save(out_lr_path, format=\"PNG\", optimize=True)\n",
    "            \n",
    "#         else:\n",
    "#             out.save(out_lr_path, format=\"JPEG\", quality=quality, optimize=True)\n",
    "#         img.save(out_hr_path, format='JPEG', quality=quality, optimize=True)\n",
    "    \n",
    "#     source_dir = hr_label_path\n",
    "#     # Tạo thư mục đích nếu chưa tồn tại\n",
    "    \n",
    "#     # Sao chép các file từ thư mục nguồn sang thư mục đích\n",
    "#     for filename in tqdm(os.listdir(source_dir)):\n",
    "#         source_file = os.path.join(source_dir, filename)\n",
    "#         file1 = os.path.join(output_lr_label, filename)\n",
    "#         file2 = os.path.join(output_hr_label, filename)\n",
    "#         shutil.copy(source_file, file1)\n",
    "#         shutil.copy(source_file, file2)\n",
    "#     print(\"Đã sao chép các file thành công.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-86e2cbe7a636>:25: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  isr.load_state_dict(torch.load(f'exp/weights/best_esr_40.pth', map_location=device)['model_state_dict'])\n",
      "<ipython-input-5-86e2cbe7a636>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  iqe.load_state_dict(torch.load(f'exp/bestweight/best_weight_enhance_{iqe_types}_lr_{imgsz}.pth', map_location=device)['model_state_dict'])\n",
      "<ipython-input-5-86e2cbe7a636>:30: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  iqe_sr.load_state_dict(torch.load(f'exp/Enhancer_Small_ISRout_64/best_weight.pth', map_location=device)['model_state_dict'])\n",
      "<ipython-input-5-86e2cbe7a636>:31: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  iqe_srqe.load_state_dict(torch.load(f'exp/Enhancer_Small_SRQE_64/best_weight.pth', map_location=device)['model_state_dict'])\n",
      "<ipython-input-5-86e2cbe7a636>:32: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  iqe_e2e.load_state_dict(torch.load(f'exp/bestweight/best_weight_enhance_small_e2e_fpnloss.pth', map_location=device)['model_state_dict'])\n",
      "<ipython-input-5-86e2cbe7a636>:34: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  isr_qe.load_state_dict(torch.load(f'exp/weights/best_esr_40.pth', map_location=device)['model_state_dict'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hr_img_path = f'output/test_600/images'\n",
    "hr_label_path = f'output/test_600/labels'\n",
    "iqe_types = 'small'\n",
    "imgsz = 64\n",
    "# iqe = IQE().to(device)\n",
    "if iqe_types=='small':\n",
    "    iqe = Enhancer().to(device)\n",
    "    iqe_sr = Enhancer().to(device)\n",
    "    iqe_e2e = Enhancer().to(device)\n",
    "    iqe_srqe = Enhancer().to(device)\n",
    "else:\n",
    "    iqe = Enhancer(in_nc=3, out_nc=3,nf=64, level=2, num_blocks=[2, 4, 4]).to(device)\n",
    "    iqe_sr = Enhancer(in_nc=3, out_nc=3,nf=64, level=2, num_blocks=[2, 4, 4]).to(device)\n",
    "    iqe_e2e = Enhancer(in_nc=3, out_nc=3,nf=64, level=2, num_blocks=[2, 4, 4]).to(device)\n",
    "    iqe_srqe = Enhancer(in_nc=3, out_nc=3,nf=64, level=2, num_blocks=[2, 4, 4]).to(device)\n",
    "\n",
    "isr = ESR(scale_factor=4, use_canny=True).to(device)\n",
    "# iqe = SwinIR(upscale=1, in_chans=3, img_size=126, window_size=7,img_range=255., depths=[6, 6, 6, 6, 6, 6], embed_dim=180, num_heads=[6, 6, 6, 6, 6, 6], mlp_ratio=2, upsampler='', resi_connection='1conv').to(device)\n",
    "# isr = Interpolate(scale_factor=4, mode='bicubic').to(device)\n",
    "\n",
    "# iqe_sr = IQE().to(device)\n",
    "\n",
    "isr_qe = ESR(scale_factor=4, use_canny=True).to(device)\n",
    "\n",
    "isr.load_state_dict(torch.load(f'exp/weights/best_esr_40.pth', map_location=device)['model_state_dict'])\n",
    "iqe.load_state_dict(torch.load(f'exp/bestweight/best_weight_enhance_{iqe_types}_lr_{imgsz}.pth', map_location=device)['model_state_dict'])\n",
    "\n",
    "# iqe_sr.load_state_dict(torch.load(f'exp/bestweight/best_weight_enhance_{iqe_types}_isrout_{imgsz}.pth', map_location=device)['model_state_dict'])\n",
    "# iqe_sr.load_state_dict(torch.load(f'exp/Enhancer_Small_e2e_64/best_iqe_weight.pth', map_location=device)['model_state_dict'])\n",
    "iqe_sr.load_state_dict(torch.load(f'exp/Enhancer_Small_ISRout_64/best_weight.pth', map_location=device)['model_state_dict'])\n",
    "iqe_srqe.load_state_dict(torch.load(f'exp/Enhancer_Small_SRQE_64/best_weight.pth', map_location=device)['model_state_dict'])\n",
    "iqe_e2e.load_state_dict(torch.load(f'exp/bestweight/best_weight_enhance_small_e2e_fpnloss.pth', map_location=device)['model_state_dict'])\n",
    "\n",
    "isr_qe.load_state_dict(torch.load(f'exp/weights/best_esr_40.pth', map_location=device)['model_state_dict'])\n",
    "# iqe_e2e = iqe_sr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics import PeakSignalNoiseRatio, StructuralSimilarityIndexMeasure\n",
    "\n",
    "def calculate_metrics(img1, img2, max_pixel_value=1.0):\n",
    "    psnr = PeakSignalNoiseRatio(data_range=1.0).to(device)\n",
    "    ssim = StructuralSimilarityIndexMeasure(data_range=1.0).to(device)\n",
    "    psnr_value = psnr(img1, img2)\n",
    "    ssim_value = ssim(img1, img2)\n",
    "    return psnr_value, ssim_value\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # for (sub, model) in zip(['LR', 'Bicubic','HQSR_C', 'HQSR_S', 'EDSR', 'SRResNet', 'VDSR', 'SRCNN', 'HR'], [lr, bicubic, esr_canny, esr_sobel,edsr,  srresnet, vdsr, srcnn, hr]):\n",
    "# # for (sub, model) in zip([ 'ISR', 'IQE', 'ISR + IQE', 'IQE + ISR', 'IQE + ISR + IQE'], [, esr_sobel]):\n",
    "# # for quality in [10, 20, 40, 80]:\n",
    "# # for quality in [10, 20, 40, 30]:\n",
    "# for quality in test_quality:\n",
    "#     # for sub in ['ISR', 'IQE','ISR + IQE', 'IQE + ISR', 'IQE + ISR + IQE']:\n",
    "#     # for sub in ['ISR', 'IQE','IQE + ISR', 'ISR + IQE']:\n",
    "#     # for sub in ['ISR + IQE' ]:\n",
    "#     for sub in ['SRQE']:\n",
    "#     # iqe_sr = iqe\n",
    "#     # isr_qe = isr\n",
    "#     # for sub in quality_subs:\n",
    "#         for part in ['train', 'test']:\n",
    "#             print(f\"Running {sub} on quality {quality}...\")\n",
    "#             hr_image_dir = f'dataset/40_e2e/{part}/LQ'\n",
    "#             lr_image_dir = f'dataset/40_e2e/{part}/LQ'\n",
    "#             # lr_image_dir = hr_image_dir\n",
    "#             output_image_dir = f'dataset/40_e2e/{part}/SRQE'\n",
    "#             os.makedirs(output_image_dir, exist_ok = True)\n",
    "#             # Duyệt qua các ảnh trong thư mục\n",
    "#             lr_image_files = os.listdir(lr_image_dir)\n",
    "#             hr_image_files = os.listdir(hr_image_dir)\n",
    "#             lr_image_files.sort()\n",
    "#             hr_image_files.sort()\n",
    "        \n",
    "#             psnr_dict = {\n",
    "#                 \"mouse_bite\" :[],\n",
    "#                 \"spur_\":[], \n",
    "#                 \"missing_hole\":[],\n",
    "#                 \"short\":[],\n",
    "#                 \"open_circuit\":[],\n",
    "#                 \"spurious_copper\":[]\n",
    "        \n",
    "#             }\n",
    "#             ssim_dict = {\n",
    "#                 \"mouse_bite\" :[],\n",
    "#                 \"spur_\":[], \n",
    "#                 \"missing_hole\":[],\n",
    "#                 \"short\":[],\n",
    "#                 \"open_circuit\":[],\n",
    "#                 \"spurious_copper\":[]\n",
    "        \n",
    "#             }\n",
    "            \n",
    "#             start = time.time()\n",
    "#             transform = transforms.ToTensor()\n",
    "#             print(lr_image_dir)\n",
    "#             with torch.no_grad():\n",
    "#                 for lr_image_file, hr_image_file in tqdm(zip(lr_image_files, hr_image_files), unit = 'img'):\n",
    "#                     # Đường dẫn đến ảnh\n",
    "                    \n",
    "#                     lr_image_path = os.path.join(lr_image_dir, lr_image_file)\n",
    "#                     hr_image_path = os.path.join(hr_image_dir, hr_image_file)\n",
    "#                     output_image_path = os.path.join(output_image_dir, hr_image_file)\n",
    "        \n",
    "#                     # Tải và chuyển đổi ảnh\n",
    "#                     lr_image = Image.open(lr_image_path).convert('RGB')\n",
    "#                     hr_image = Image.open(hr_image_path).convert('RGB')\n",
    "#                     hr_image = hr_image.resize((608, 608))\n",
    "#                     lr_image = lr_image.resize((152, 152))\n",
    "#                     if sub == 'IQE':\n",
    "#                         hr_image = hr_image.resize((152, 152))\n",
    "#                     # lr_image = Image.open(lr_image_path).convert('RGB')\n",
    "        \n",
    "#                     lr_image = transform(lr_image).unsqueeze(0).to(device)  # Thêm batch dimension và chuyển sang GPU\n",
    "#                     hr_image = transform(hr_image).unsqueeze(0).to(device)  # Thêm batch dimension và chuyển sang GPU\n",
    "#                     # if model == bicubic:\n",
    "#                     # Dự đoán\n",
    "#                     if sub == 'ISR':\n",
    "#                         output = isr(lr_image)\n",
    "#                     elif sub == 'IQE':\n",
    "#                         output = iqe(lr_image)\n",
    "#                     elif sub == 'ISR + IQE':\n",
    "#                         output = iqe_sr(isr(lr_image))\n",
    "#                     elif sub == 'IQE + ISR':\n",
    "#                         output = isr(iqe(lr_image))\n",
    "#                     elif sub == 'IQE + ISR + IQE':\n",
    "#                         output = iqe_sr(isr_qe(iqe(lr_image)))\n",
    "#                     elif sub == 'e2e':\n",
    "#                         output = iqe_e2e(isr(lr_image))\n",
    "#                     elif sub == 'SRQE':\n",
    "#                         output = iqe_srqe(isr(lr_image))\n",
    "#                     psnr,ssim = calculate_metrics(output, hr_image)\n",
    "#                     for key in psnr_dict.keys():\n",
    "#                         if key in lr_image_path:\n",
    "#                             psnr_dict[key].append(psnr)\n",
    "#                             ssim_dict[key].append(ssim)\n",
    "#                             break\n",
    "\n",
    "#                     # Chuyển đổi tensor đầu ra thành ảnh và lưu\n",
    "#                     output_image = output.squeeze(0).to(device)  # Loại bỏ batch dimension và chuyển tensor sang CPU\n",
    "#                     output_image = transforms.ToPILImage()(output_image)  # Chuyển tensor thành ảnh PIL\n",
    "#                     output_image.save(output_image_path, )  # Lưu ảnh\n",
    "#             avg_psnr = [0, 0, 0, 0, 0, 0]\n",
    "#             avg_ssim = [0, 0, 0, 0, 0, 0]\n",
    "\n",
    "\n",
    "#             # Tính toán PSNR trung bình\n",
    "#             avg_psnr[0] = sum(psnr_dict['mouse_bite'])/len(psnr_dict['mouse_bite']) #mousebite_psnr\n",
    "#             avg_psnr[1] = sum(psnr_dict['spur_'])/len(psnr_dict['spur_']) #spur_psnr\n",
    "#             avg_psnr[2] = sum(psnr_dict['missing_hole'])/len(psnr_dict['missing_hole']) #missinghole_psnr \n",
    "#             avg_psnr[3] = sum(psnr_dict['short'])/len(psnr_dict['short']) #short_psnr\n",
    "#             avg_psnr[4] = sum(psnr_dict['open_circuit'])/len(psnr_dict['open_circuit']) #opencircuit_psnr\n",
    "#             avg_psnr[5]= sum(psnr_dict['spurious_copper'])/len(psnr_dict['spurious_copper']) #spuriouscopper_psnr \n",
    "#             average_psnr = sum(avg_psnr)/len(avg_psnr)\n",
    "\n",
    "#             avg_ssim[0] = sum(ssim_dict['mouse_bite'])/len(ssim_dict['mouse_bite']) #mousebite_ssim\n",
    "#             avg_ssim[1] = sum(ssim_dict['spur_'])/len(ssim_dict['spur_']) #spur_ssim\n",
    "#             avg_ssim[2] = sum(ssim_dict['missing_hole'])/len(ssim_dict['missing_hole']) #missinghole_ssim \n",
    "#             avg_ssim[3] = sum(ssim_dict['short'])/len(ssim_dict['short']) #short_ssim\n",
    "#             avg_ssim[4] = sum(ssim_dict['open_circuit'])/len(ssim_dict['open_circuit']) #opencircuit_ssim\n",
    "#             avg_ssim[5]= sum(ssim_dict['spurious_copper'])/len(ssim_dict['spurious_copper']) #spuriouscopper_ssim  \n",
    "#             average_ssim = sum(avg_ssim)/len(avg_ssim)\n",
    "#             end = time.time()\n",
    "\n",
    "#             with open('runs/enhance_results.txt', 'a') as f:\n",
    "#                 f.write(output_image_dir.split('/')[1] + '\\n')\n",
    "#                 f.write(f'missinghole_psnr: {avg_psnr[2]:.2f}' + '\\n')\n",
    "#                 f.write(f'mousebite_psnr: {avg_psnr[0]:.2f}' + '\\n')\n",
    "#                 f.write(f'opencircuit_psnr: {avg_psnr[4]:.2f}' + '\\n')\n",
    "#                 f.write(f'short_psnr: {avg_psnr[3]:.2f}' + '\\n')\n",
    "#                 f.write(f'spur_psnr: {avg_psnr[1]:.2f}' + '\\n')\n",
    "#                 f.write(f'spuriouscopper_psnr: {avg_psnr[5]:.2f}' + '\\n')\n",
    "#                 f.write(f'average_psnr: {average_psnr:.2f}' + '\\n')\n",
    "#                 f.write(f'time process: {end - start:.2f}' + '\\n')\n",
    "\n",
    "#                 f.write(f'missinghole_psnr: {avg_ssim[2]:.4f}' + '\\n')\n",
    "#                 f.write(f'mousebite_psnr: {avg_ssim[0]:.4f}' + '\\n')\n",
    "#                 f.write(f'opencircuit_psnr: {avg_ssim[4]:.4f}' + '\\n')\n",
    "#                 f.write(f'short_psnr: {avg_ssim[3]:.4f}' + '\\n')\n",
    "#                 f.write(f'spur_psnr: {avg_ssim[1]:.4f}' + '\\n')\n",
    "#                 f.write(f'spuriouscopper_psnr: {avg_ssim[5]:.4f}' + '\\n')\n",
    "#                 f.write(f'average_psnr: {average_ssim:.4f}' + '\\n')\n",
    "#                 f.write(f'time process: {end - start:.4f}' + '\\n')\n",
    "#                 f.write('\\n')\n",
    "#                 f.flush()\n",
    "#             source_dir = hr_label_path\n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running e2e on quality 40...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0img [00:00, ?img/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0img [00:01, ?img/s]\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 92.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 81.38 MiB is free. Process 30678 has 31.20 GiB memory in use. Process 85264 has 470.00 MiB memory in use. Of the allocated memory 81.17 MiB is allocated by PyTorch, and 20.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-7da3ac5500a5>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     76\u001b[0m                     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miqe_sr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0misr_qe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miqe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0msub\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'e2e'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m                     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miqe_e2e\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0misr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0msub\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'SRQE'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m                     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miqe_srqe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0misr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/work/u9564043/Machine-Vision/models/esr.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresidual_layers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupsample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    217\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    452\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 454\u001b[0;31m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    455\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 92.00 MiB. GPU 0 has a total capacity of 31.74 GiB of which 81.38 MiB is free. Process 30678 has 31.20 GiB memory in use. Process 85264 has 470.00 MiB memory in use. Of the allocated memory 81.17 MiB is allocated by PyTorch, and 20.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "# for (sub, model) in zip(['LR', 'Bicubic','HQSR_C', 'HQSR_S', 'EDSR', 'SRResNet', 'VDSR', 'SRCNN', 'HR'], [lr, bicubic, esr_canny, esr_sobel,edsr,  srresnet, vdsr, srcnn, hr]):\n",
    "# for (sub, model) in zip([ 'ISR', 'IQE', 'ISR + IQE', 'IQE + ISR', 'IQE + ISR + IQE'], [, esr_sobel]):\n",
    "# for quality in [10, 20, 40, 80]:\n",
    "# for quality in [10, 20, 40, 30]:\n",
    "for quality in test_quality:\n",
    "    # for sub in ['ISR', 'IQE','ISR + IQE', 'IQE + ISR', 'IQE + ISR + IQE']:\n",
    "    # for sub in ['ISR', 'IQE','IQE + ISR', 'ISR + IQE']:\n",
    "    # for sub in ['ISR + IQE' ]:\n",
    "    for sub in ['e2e']:\n",
    "    # iqe_sr = iqe\n",
    "    # isr_qe = isr\n",
    "    # for sub in quality_subs:\n",
    "        print(f\"Running {sub} on quality {quality}...\")\n",
    "        hr_image_dir = hr_img_path\n",
    "        lr_image_dir = f'output/test_{quality}_150/images'\n",
    "        # lr_image_dir = hr_image_dir\n",
    "        output_image_dir = f'output/enhance_{iqe_types}{imgsz}/test_{quality}_150_{sub}/images'\n",
    "        os.makedirs(output_image_dir, exist_ok = True)\n",
    "        # Duyệt qua các ảnh trong thư mục\n",
    "        lr_image_files = os.listdir(lr_image_dir)\n",
    "        hr_image_files = os.listdir(hr_image_dir)\n",
    "        lr_image_files.sort()\n",
    "        hr_image_files.sort()\n",
    "    \n",
    "        psnr_dict = {\n",
    "            \"mouse_bite\" :[],\n",
    "            \"spur_\":[], \n",
    "            \"missing_hole\":[],\n",
    "            \"short\":[],\n",
    "            \"open_circuit\":[],\n",
    "            \"spurious_copper\":[]\n",
    "    \n",
    "        }\n",
    "        ssim_dict = {\n",
    "            \"mouse_bite\" :[],\n",
    "            \"spur_\":[], \n",
    "            \"missing_hole\":[],\n",
    "            \"short\":[],\n",
    "            \"open_circuit\":[],\n",
    "            \"spurious_copper\":[]\n",
    "    \n",
    "        }\n",
    "        \n",
    "        start = time.time()\n",
    "        transform = transforms.ToTensor()\n",
    "        with torch.no_grad():\n",
    "            for lr_image_file, hr_image_file in tqdm(zip(lr_image_files, hr_image_files), unit = 'img'):\n",
    "                # Đường dẫn đến ảnh\n",
    "                \n",
    "                lr_image_path = os.path.join(lr_image_dir, lr_image_file)\n",
    "                hr_image_path = os.path.join(hr_image_dir, hr_image_file)\n",
    "                output_image_path = os.path.join(output_image_dir, hr_image_file)\n",
    "    \n",
    "                # Tải và chuyển đổi ảnh\n",
    "                lr_image = Image.open(lr_image_path).convert('RGB')\n",
    "                hr_image = Image.open(hr_image_path).convert('RGB')\n",
    "                hr_image = hr_image.resize((608, 608))\n",
    "                lr_image = lr_image.resize((152, 152))\n",
    "                if sub == 'IQE':\n",
    "                    hr_image = hr_image.resize((152, 152))\n",
    "                # lr_image = Image.open(lr_image_path).convert('RGB')\n",
    "    \n",
    "                lr_image = transform(lr_image).unsqueeze(0).to(device)  # Thêm batch dimension và chuyển sang GPU\n",
    "                hr_image = transform(hr_image).unsqueeze(0).to(device)  # Thêm batch dimension và chuyển sang GPU\n",
    "                # if model == bicubic:\n",
    "                # Dự đoán\n",
    "                if sub == 'ISR':\n",
    "                    output = isr(lr_image)\n",
    "                elif sub == 'IQE':\n",
    "                    output = iqe(lr_image)\n",
    "                elif sub == 'ISR + IQE':\n",
    "                    output = iqe_sr(isr(lr_image))\n",
    "                elif sub == 'IQE + ISR':\n",
    "                    output = isr(iqe(lr_image))\n",
    "                elif sub == 'IQE + ISR + IQE':\n",
    "                    output = iqe_sr(isr_qe(iqe(lr_image)))\n",
    "                elif sub == 'e2e':\n",
    "                    output = iqe_e2e(isr(lr_image))\n",
    "                elif sub == 'SRQE':\n",
    "                    output = iqe_srqe(isr(lr_image))\n",
    "                psnr,ssim = calculate_metrics(output, hr_image)\n",
    "                for key in psnr_dict.keys():\n",
    "                    if key in lr_image_path:\n",
    "                        psnr_dict[key].append(psnr)\n",
    "                        ssim_dict[key].append(ssim)\n",
    "                        break\n",
    "\n",
    "                # Chuyển đổi tensor đầu ra thành ảnh và lưu\n",
    "                output_image = output.squeeze(0).to(device)  # Loại bỏ batch dimension và chuyển tensor sang CPU\n",
    "                output_image = transforms.ToPILImage()(output_image)  # Chuyển tensor thành ảnh PIL\n",
    "                output_image.save(output_image_path, )  # Lưu ảnh\n",
    "        avg_psnr = [0, 0, 0, 0, 0, 0]\n",
    "        avg_ssim = [0, 0, 0, 0, 0, 0]\n",
    "\n",
    "\n",
    "        # Tính toán PSNR trung bình\n",
    "        avg_psnr[0] = sum(psnr_dict['mouse_bite'])/len(psnr_dict['mouse_bite']) #mousebite_psnr\n",
    "        avg_psnr[1] = sum(psnr_dict['spur_'])/len(psnr_dict['spur_']) #spur_psnr\n",
    "        avg_psnr[2] = sum(psnr_dict['missing_hole'])/len(psnr_dict['missing_hole']) #missinghole_psnr \n",
    "        avg_psnr[3] = sum(psnr_dict['short'])/len(psnr_dict['short']) #short_psnr\n",
    "        avg_psnr[4] = sum(psnr_dict['open_circuit'])/len(psnr_dict['open_circuit']) #opencircuit_psnr\n",
    "        avg_psnr[5]= sum(psnr_dict['spurious_copper'])/len(psnr_dict['spurious_copper']) #spuriouscopper_psnr \n",
    "        average_psnr = sum(avg_psnr)/len(avg_psnr)\n",
    "\n",
    "        avg_ssim[0] = sum(ssim_dict['mouse_bite'])/len(ssim_dict['mouse_bite']) #mousebite_ssim\n",
    "        avg_ssim[1] = sum(ssim_dict['spur_'])/len(ssim_dict['spur_']) #spur_ssim\n",
    "        avg_ssim[2] = sum(ssim_dict['missing_hole'])/len(ssim_dict['missing_hole']) #missinghole_ssim \n",
    "        avg_ssim[3] = sum(ssim_dict['short'])/len(ssim_dict['short']) #short_ssim\n",
    "        avg_ssim[4] = sum(ssim_dict['open_circuit'])/len(ssim_dict['open_circuit']) #opencircuit_ssim\n",
    "        avg_ssim[5]= sum(ssim_dict['spurious_copper'])/len(ssim_dict['spurious_copper']) #spuriouscopper_ssim  \n",
    "        average_ssim = sum(avg_ssim)/len(avg_ssim)\n",
    "        end = time.time()\n",
    "\n",
    "        with open('runs/enhance_results.txt', 'a') as f:\n",
    "            f.write(output_image_dir.split('/')[1] + '\\n')\n",
    "            f.write(f'missinghole_psnr: {avg_psnr[2]:.2f}' + '\\n')\n",
    "            f.write(f'mousebite_psnr: {avg_psnr[0]:.2f}' + '\\n')\n",
    "            f.write(f'opencircuit_psnr: {avg_psnr[4]:.2f}' + '\\n')\n",
    "            f.write(f'short_psnr: {avg_psnr[3]:.2f}' + '\\n')\n",
    "            f.write(f'spur_psnr: {avg_psnr[1]:.2f}' + '\\n')\n",
    "            f.write(f'spuriouscopper_psnr: {avg_psnr[5]:.2f}' + '\\n')\n",
    "            f.write(f'average_psnr: {average_psnr:.2f}' + '\\n')\n",
    "            f.write(f'time process: {end - start:.2f}' + '\\n')\n",
    "\n",
    "            f.write(f'missinghole_psnr: {avg_ssim[2]:.4f}' + '\\n')\n",
    "            f.write(f'mousebite_psnr: {avg_ssim[0]:.4f}' + '\\n')\n",
    "            f.write(f'opencircuit_psnr: {avg_ssim[4]:.4f}' + '\\n')\n",
    "            f.write(f'short_psnr: {avg_ssim[3]:.4f}' + '\\n')\n",
    "            f.write(f'spur_psnr: {avg_ssim[1]:.4f}' + '\\n')\n",
    "            f.write(f'spuriouscopper_psnr: {avg_ssim[5]:.4f}' + '\\n')\n",
    "            f.write(f'average_psnr: {average_ssim:.4f}' + '\\n')\n",
    "            f.write(f'time process: {end - start:.4f}' + '\\n')\n",
    "            f.write('\\n')\n",
    "            f.flush()\n",
    "        source_dir = hr_label_path\n",
    "    \n",
    "        dest = f'output/enhance_{iqe_types}{imgsz}/test_{quality}_150_{sub}/labels'\n",
    "    \n",
    "        # Tạo thư mục đích nếu chưa tồn tại\n",
    "        \n",
    "        os.makedirs(dest, exist_ok=True)\n",
    "    \n",
    "        # Sao chép các file từ thư mục nguồn sang thư mục đích\n",
    "        for filename in os.listdir(source_dir):\n",
    "            source_file = os.path.join(source_dir, filename)\n",
    "            file1 = os.path.join(dest, filename)\n",
    "    \n",
    "            shutil.copy(source_file, file1)\n",
    "    \n",
    "        # print(\"Đã sao chép các file thành công.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/u9564043/.local/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ultralytics\n",
    "from ultralytics import YOLO\n",
    "from PIL import ImageDraw, ImageFont\n",
    "import yaml\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import random \n",
    "from torchmetrics.detection.mean_ap import MeanAveragePrecision\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from ultralytics.utils import ops\n",
    "yolov8 = YOLO('exp/weights/bestyolov8.pt').model\n",
    "yolov9 = YOLO()\n",
    "\n",
    "yolov8_e2e = YOLO('exp/weights/bestyolov8.pt').model\n",
    "yolov8_e2e.load_state_dict(torch.load('exp/Enhancer_Small_e2e_64/best_detection_weight.pth')['model_state_dict'])\n",
    "yolov8_srqe = YOLO('exp/weights/bestyolov8.pt').model\n",
    "yolov8_srqe.load_state_dict(torch.load('exp/YOLOv8_SRQE_fintune/best_detection_weight.pth')['model_state_dict'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating output/enhance_small64/test_40_150_e2e dataset at QF 40...\n",
      "Running inference with on _e2e...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Val on _e2e:   0%|          | 0/1068 [00:00<?, ?batch/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for on _e2e:\n",
      "Class 0: mAP@50 = 0.727\n",
      "Class 1: mAP@50 = 0.683\n",
      "Class 2: mAP@50 = 0.975\n",
      "Class 3: mAP@50 = 0.757\n",
      "Class 4: mAP@50 = 0.833\n",
      "Class 5: mAP@50 = 0.728\n",
      "tensor(0.7838)\n",
      "--------------------------------------------------\n",
      "Evaluating output/enhance_small64/test_40_150_SRQE dataset at QF 40...\n",
      "Running inference with on _SRQE...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for on _SRQE:\n",
      "Class 0: mAP@50 = 0.768\n",
      "Class 1: mAP@50 = 0.643\n",
      "Class 2: mAP@50 = 0.934\n",
      "Class 3: mAP@50 = 0.694\n",
      "Class 4: mAP@50 = 0.822\n",
      "Class 5: mAP@50 = 0.664\n",
      "tensor(0.7542)\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from PIL import ImageDraw, ImageFont\n",
    "import yaml\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import random \n",
    "from torchmetrics.detection.mean_ap import MeanAveragePrecision\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from ultralytics.utils import ops\n",
    "\n",
    "\n",
    "\n",
    "class_names = {\n",
    "    0: 'mouse_bite',\n",
    "    1: 'spur',\n",
    "    2: 'missing_hole',\n",
    "    3: 'short',\n",
    "    4: 'open_circuit',\n",
    "    5: 'spurious_copper'\n",
    "}\n",
    "label_colors = {\n",
    "    0: (255, 0, 0),  # Red\n",
    "    1: (0, 255, 0),  # Green\n",
    "    2: (0, 0, 255),  # Blue\n",
    "    3: (255, 255, 0),  # Yellow\n",
    "    4: (255, 0, 255),  # Magenta\n",
    "    5: (0, 255, 255)   # Cyan\n",
    "}\n",
    "def draw_and_save_predictions(image, boxes, labels, scores, class_names, save_path=None, font_path=None):\n",
    "    \"\"\"\n",
    "    Vẽ bounding box, nhãn và độ tự tin lên ảnh, sau đó lưu ảnh nếu cần.\n",
    "    \n",
    "    Args:\n",
    "        image (PIL.Image.Image): Ảnh đầu vào.\n",
    "        boxes (torch.Tensor): Tensor chứa các bounding box, định dạng [x1, y1, x2, y2].\n",
    "        labels (torch.Tensor): Tensor chứa nhãn các bounding box.\n",
    "        scores (torch.Tensor): Tensor chứa điểm tự tin của các bounding box.\n",
    "        class_names (dict): Mapping từ ID nhãn sang tên lớp.\n",
    "        save_path (str): Đường dẫn để lưu ảnh (nếu không truyền, ảnh sẽ không được lưu).\n",
    "        font_path (str): Đường dẫn tới file font TrueType (nếu không truyền sẽ dùng font mặc định).\n",
    "    \n",
    "    Returns:\n",
    "        PIL.Image.Image: Ảnh đã được vẽ bounding box.\n",
    "    \"\"\"\n",
    "    # Tạo bản sao ảnh để vẽ\n",
    "    draw_image = image.copy()\n",
    "    draw = ImageDraw.Draw(draw_image)\n",
    "    \n",
    "    # Tải font (nếu có)\n",
    "    if font_path:\n",
    "        try:\n",
    "            font = ImageFont.truetype(font_path, size=20)\n",
    "        except Exception as e:\n",
    "            print(f\"Không thể tải font từ {font_path}. Sử dụng font mặc định.\")\n",
    "            font = ImageFont.load_default()\n",
    "    else:\n",
    "        font = ImageFont.load_default()\n",
    "    \n",
    "    # Vẽ từng bounding box\n",
    "    for box, label, score in zip(boxes, labels, scores):\n",
    "        x1, y1, x2, y2 = box\n",
    "        label_text = f\"{class_names.get(label.item(), 'Unknown')} {score:.2f}\"\n",
    "        color = label_colors.get(label.item())\n",
    "        # Vẽ hình chữ nhật\n",
    "        draw.rectangle([x1, y1, x2, y2], outline=color, width=2)\n",
    "        \n",
    "        # Vẽ nhãn với nền\n",
    "        if hasattr(draw, \"textbbox\"):\n",
    "            text_bbox = draw.textbbox((x1, y1), label_text, font=font)\n",
    "            text_width, text_height = text_bbox[2] - text_bbox[0], text_bbox[3] - text_bbox[1]\n",
    "        # else:\n",
    "            # text_width, text_height = draw.textsize(label_text, font=font)\n",
    "        draw.rectangle(\n",
    "            [x1, y1 - text_height, x1 + text_width, y1],\n",
    "            fill=color\n",
    "        )\n",
    "        draw.text((x1, y1 - text_height), label_text, fill=\"white\", font=font)\n",
    "    \n",
    "    # Lưu ảnh nếu `save_path` được cung cấp\n",
    "    if save_path:\n",
    "        draw_image.save(save_path)\n",
    "        # plt.imshow(draw_image)\n",
    "        # print(f\"Ảnh đã được lưu tại: {save_path}\")\n",
    "\n",
    "\n",
    "\n",
    "def yolo_to_xyxy(bboxes, img_w, img_h):\n",
    "    \"\"\"\n",
    "    Convert YOLO-format [cx, cy, w, h] normalized -> [x1, y1, x2, y2] absolute\n",
    "    \"\"\"\n",
    "    cx, cy, w, h = bboxes[:, 0], bboxes[:, 1], bboxes[:, 2], bboxes[:, 3]\n",
    "    x1 = (cx - w/2) * img_w\n",
    "    y1 = (cy - h/2) * img_h\n",
    "    x2 = (cx + w/2) * img_w\n",
    "    y2 = (cy + h/2) * img_h\n",
    "    return torch.stack([x1, y1, x2, y2], dim=1)\n",
    "\n",
    "def run_inference(image, model):\n",
    "    results = model.predict(image, verbose=False)\n",
    "    predictions = results[0].boxes\n",
    "    # Convert to numpy for WBF compatibility\n",
    "    boxes = predictions.xyxy.cpu().numpy()\n",
    "    scores = predictions.conf.cpu().numpy()\n",
    "    labels = predictions.cls.cpu().numpy()\n",
    "    return boxes, scores, labels\n",
    "\n",
    "def normalize_boxes(boxes, image_size):\n",
    "    \"\"\"Normalize box coordinates to [0, 1] range\"\"\"\n",
    "    width, height = image_size\n",
    "    normalized_boxes = boxes.copy()\n",
    "    normalized_boxes[:, [0, 2]] /= width\n",
    "    normalized_boxes[:, [1, 3]] /= height\n",
    "    return normalized_boxes\n",
    "\n",
    "def denormalize_boxes(boxes, image_size):\n",
    "    \"\"\"Convert normalized boxes back to pixel coordinates\"\"\"\n",
    "    width, height = image_size\n",
    "    denormalized_boxes = boxes.copy()\n",
    "    denormalized_boxes[:, [0, 2]] *= width\n",
    "    denormalized_boxes[:, [1, 3]] *= height\n",
    "    return denormalized_boxes\n",
    "\n",
    "def ensemble_inference(image, method):\n",
    "    # Get predictions from both models\n",
    "    boxes_yolov8, scores_yolov8, labels_yolov8 = run_inference(image, yolov8)\n",
    "    boxes_yolov9, scores_yolov9, labels_yolov9 = run_inference(image, yolov9)\n",
    "    # print(boxes_yolov8)\n",
    "    # Get image size\n",
    "    if isinstance(image, torch.Tensor):\n",
    "        height, width = image.shape[-2:]\n",
    "    else:  # PIL Image\n",
    "        width, height = image.size\n",
    "    image_size = (width, height)\n",
    "    if method == 'yolov8':\n",
    "        boxes, scores, labels = boxes_yolov8, scores_yolov8, labels_yolov8\n",
    "    else:\n",
    "        boxes, scores, labels = boxes_yolov9, scores_yolov9, labels_yolov9\n",
    "   \n",
    "    # Convert back to torch tensors\n",
    "    boxes = torch.from_numpy(boxes).float()\n",
    "    scores = torch.from_numpy(scores).float()\n",
    "    labels = torch.from_numpy(labels).long()\n",
    "    return boxes, scores, labels\n",
    "\n",
    "def read_label_file(label_path, img_width, img_height):\n",
    "    boxes = []\n",
    "    labels = []\n",
    "    with open(label_path, \"r\") as f:\n",
    "        for line in f:\n",
    "            box = list(map(float, line.strip().split()))\n",
    "            labels.append(int(box[0]))\n",
    "            boxes.append(yolo_to_xyxy(box, img_width, img_height))\n",
    "    return boxes, labels\n",
    "\n",
    "log_fp = open('runs/detect_results.txt', 'a')\n",
    "# iqe_types = 'small'\n",
    "# imgsz = 64\n",
    "# detect_subs = ['_IQE', '_ISR + IQE', '_IQE + ISR', '_IQE + ISR + IQE', '_e2e']\n",
    "for quality in test_quality:\n",
    "\n",
    "    # for sub in ['','_ISR','_IQE', '_ISR + IQE', '_IQE + ISR', '_IQE + ISR + IQE', 'full']:\n",
    "    # for sub in ['','_ISR', '_IQE', '_ISR + IQE', '_IQE + ISR', 'full']:\n",
    "    # for sub in ['_IQE + ISR + IQE' ]:\n",
    "    for sub in ['_e2e', '_SRQE' ]:\n",
    "    # for sub in detect_subs:\n",
    "        # Tạo thư mục gốc cho inference\n",
    "        base_output_dir = \"runs\"\n",
    "        os.makedirs(base_output_dir, exist_ok=True)\n",
    "        path = f'output/enhance_{iqe_types}{imgsz}/test_{quality}_150{sub}'\n",
    "        # path = '/kaggle/input/test600/test1_600x600'\n",
    "\n",
    "        if sub == 'full':\n",
    "            path = f'output/test_{quality}_600' \n",
    "        data = {\n",
    "            'train': f'/kaggle/input/tesstt/images',\n",
    "            'val': f'{path}/images',\n",
    "            'nc': 6,\n",
    "            'names': {\n",
    "                0: 'mouse_bite',\n",
    "                1: 'spur',\n",
    "                2: 'missing_hole',\n",
    "                3: 'short',\n",
    "                4: 'open_circuit',\n",
    "                5: 'spurious_copper'\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        with open('output/data.yaml', 'w') as file:\n",
    "            yaml.dump(data, file, default_flow_style=False)\n",
    "    \n",
    "        print(f\"Evaluating {path} dataset at QF {quality}...\")\n",
    "        log_fp.write(f\"Evaluating {path} dataset at QF {quality}..\\n\")\n",
    "        log_fp.flush()\n",
    "\n",
    "        # # Run individual model validation\n",
    "        # results1 = yolov8.val(data='output/data.yaml', batch=1)\n",
    "        # results2 = yolov9.val(data='output/data.yaml', batch=1)\n",
    "    \n",
    "        # path = f'output/test_{quality}_150{sub}'\n",
    "        # path = '/kaggle/input/test600/test1_600x600'\n",
    "        images_dir = f\"{path}/images\"\n",
    "        images_files = sorted(os.listdir(images_dir))\n",
    "        labels_dir = f\"{path}/labels\"\n",
    "        labels_files = sorted(os.listdir(labels_dir))\n",
    "\n",
    "        valid_dataset = YOLOTestDataset(images_dir, labels_dir)\n",
    "        valid_loader = DataLoader(valid_dataset, collate_fn=yolo_collate_fn)\n",
    "        # Initialize Mean Average Precision metric\n",
    "        map_metric = MeanAveragePrecision(iou_thresholds=[0.5], iou_type=\"bbox\", class_metrics=True)\n",
    "        \n",
    "        # for method in ['yolov8', 'yolov9',  'nms', 'soft_nms','nmw','wbf']:\n",
    "        if sub == '_e2e':\n",
    "            detection = yolov8_e2e\n",
    "        elif sub == '_SRQE':\n",
    "            detection = yolov8_srqe\n",
    "        else:\n",
    "            detection = yolov8\n",
    "        detection.to(device)\n",
    "        detection.eval()\n",
    "        map_metric.reset()\n",
    "        print(f\"Running inference with on {sub}...\")\n",
    "        # Tạo thư mục riêng cho từng phương pháp\n",
    "        method_output_dir = os.path.join(base_output_dir, sub)\n",
    "        os.makedirs(method_output_dir, exist_ok=True)\n",
    "\n",
    "        pbar = tqdm(valid_loader, desc=f'Val on {sub}', unit='batch', leave=False)\n",
    "        for i, (hr_images, labels) in enumerate(pbar):\n",
    "            hr_images = hr_images.to(device)  # (B T C H W)s\n",
    "\n",
    "            pred = detection(hr_images)    \n",
    "\n",
    "            preds_for_metric = ops.non_max_suppression(pred,\n",
    "                                                       conf_thres=0.25, # low conf for mAP\n",
    "                                                       iou_thres=0.5,\n",
    "                                                       agnostic=False,\n",
    "                                                       max_det=300,\n",
    "                                                       nc=data['nc'])\n",
    "            predictions, targets = post_process(preds_for_metric, labels, 608, 608)             \n",
    "            # print(f'pred: {predictions}\\nlabels: {targets}')\n",
    "\n",
    "            map_metric.update(predictions, targets)    \n",
    "            # Vẽ và lưu ảnh\n",
    "            # flag = bool(random.randint(0, 1))\n",
    "            # if flag:\n",
    "            save_path = os.path.join(method_output_dir, images_files[i])  # Lưu với cùng tên ảnh\n",
    "            draw_and_save_predictions(\n",
    "                image=transforms.ToPILImage()(hr_images.squeeze(0).cpu()).copy(),\n",
    "                boxes=predictions[0]['boxes'].numpy(),\n",
    "                labels=predictions[0]['labels'].numpy(),\n",
    "                scores=predictions[0]['scores'].numpy(),\n",
    "                class_names=data['names'],\n",
    "                save_path=save_path\n",
    "            )\n",
    "\n",
    "        # Tính toán kết quả sau khi xử lý tất cả ảnh\n",
    "        results = map_metric.compute()\n",
    "        print(f\"\\nResults for on {sub}:\")\n",
    "        log_fp.write(f\"\\nResults for on {sub}:\\n\")\n",
    "        map50_per_class = results['map_per_class']\n",
    "        for class_idx, map_value in enumerate(map50_per_class):\n",
    "            print(f\"Class {class_idx}: mAP@50 = {map_value.item():.3f}\")\n",
    "            log_fp.write(f\"Class {class_idx}: mAP@50 = {map_value.item():.3f}\\n\")\n",
    "            log_fp.flush()\n",
    "        print(results['map'])\n",
    "        log_fp.write(f\"Average: {results['map']:.3f}\\n\")\n",
    "        log_fp.flush()\n",
    "        print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating _IQE dataset at QF 40...\n",
      "Running yolov8 inference with on _IQE...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1068 [00:00<00:21, 49.25img/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1068/1068 [00:19<00:00, 53.84img/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for yolov8 on _IQE:\n",
      "Class 0: mAP@50 = 0.125\n",
      "Class 1: mAP@50 = 0.038\n",
      "Class 2: mAP@50 = 0.265\n",
      "Class 3: mAP@50 = 0.226\n",
      "Class 4: mAP@50 = 0.270\n",
      "Class 5: mAP@50 = 0.108\n",
      "tensor(0.1721)\n",
      "--------------------------------------------------\n",
      "Evaluating _ISR + IQE dataset at QF 40...\n",
      "Running yolov8 inference with on _ISR + IQE...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1068/1068 [00:28<00:00, 37.08img/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for yolov8 on _ISR + IQE:\n",
      "Class 0: mAP@50 = 0.422\n",
      "Class 1: mAP@50 = 0.381\n",
      "Class 2: mAP@50 = 0.909\n",
      "Class 3: mAP@50 = 0.424\n",
      "Class 4: mAP@50 = 0.543\n",
      "Class 5: mAP@50 = 0.560\n",
      "tensor(0.5399)\n",
      "--------------------------------------------------\n",
      "Evaluating _IQE + ISR dataset at QF 40...\n",
      "Running yolov8 inference with on _IQE + ISR...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1068/1068 [00:38<00:00, 27.47img/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for yolov8 on _IQE + ISR:\n",
      "Class 0: mAP@50 = 0.231\n",
      "Class 1: mAP@50 = 0.085\n",
      "Class 2: mAP@50 = 0.762\n",
      "Class 3: mAP@50 = 0.226\n",
      "Class 4: mAP@50 = 0.387\n",
      "Class 5: mAP@50 = 0.388\n",
      "tensor(0.3466)\n",
      "--------------------------------------------------\n",
      "Evaluating _IQE + ISR + IQE dataset at QF 40...\n",
      "Running yolov8 inference with on _IQE + ISR + IQE...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1068/1068 [00:28<00:00, 37.96img/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for yolov8 on _IQE + ISR + IQE:\n",
      "Class 0: mAP@50 = 0.226\n",
      "Class 1: mAP@50 = 0.110\n",
      "Class 2: mAP@50 = 0.752\n",
      "Class 3: mAP@50 = 0.223\n",
      "Class 4: mAP@50 = 0.365\n",
      "Class 5: mAP@50 = 0.381\n",
      "tensor(0.3427)\n",
      "--------------------------------------------------\n",
      "Evaluating _e2e dataset at QF 40...\n",
      "Running yolov8 inference with on _e2e...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1068/1068 [00:30<00:00, 35.45img/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for yolov8 on _e2e:\n",
      "Class 0: mAP@50 = 0.072\n",
      "Class 1: mAP@50 = 0.039\n",
      "Class 2: mAP@50 = 0.036\n",
      "Class 3: mAP@50 = 0.020\n",
      "Class 4: mAP@50 = 0.058\n",
      "Class 5: mAP@50 = 0.016\n",
      "tensor(0.0400)\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# from PIL import ImageDraw, ImageFont\n",
    "# import yaml\n",
    "# import torch\n",
    "# import numpy as np\n",
    "# from ensemble_boxes import *\n",
    "# from tqdm import tqdm\n",
    "# from PIL import Image\n",
    "# import os\n",
    "# import matplotlib.pyplot as plt\n",
    "# import random \n",
    "# from torchmetrics.detection.mean_ap import MeanAveragePrecision\n",
    "\n",
    "\n",
    "# class_names = {\n",
    "#     0: 'mouse_bite',\n",
    "#     1: 'spur',\n",
    "#     2: 'missing_hole',\n",
    "#     3: 'short',\n",
    "#     4: 'open_circuit',\n",
    "#     5: 'spurious_copper'\n",
    "# }\n",
    "# label_colors = {\n",
    "#     0: (255, 0, 0),  # Red\n",
    "#     1: (0, 255, 0),  # Green\n",
    "#     2: (0, 0, 255),  # Blue\n",
    "#     3: (255, 255, 0),  # Yellow\n",
    "#     4: (255, 0, 255),  # Magenta\n",
    "#     5: (0, 255, 255)   # Cyan\n",
    "# }\n",
    "# def draw_and_save_predictions(image, boxes, labels, scores, class_names, save_path=None, font_path=None):\n",
    "#     \"\"\"\n",
    "#     Vẽ bounding box, nhãn và độ tự tin lên ảnh, sau đó lưu ảnh nếu cần.\n",
    "    \n",
    "#     Args:\n",
    "#         image (PIL.Image.Image): Ảnh đầu vào.\n",
    "#         boxes (torch.Tensor): Tensor chứa các bounding box, định dạng [x1, y1, x2, y2].\n",
    "#         labels (torch.Tensor): Tensor chứa nhãn các bounding box.\n",
    "#         scores (torch.Tensor): Tensor chứa điểm tự tin của các bounding box.\n",
    "#         class_names (dict): Mapping từ ID nhãn sang tên lớp.\n",
    "#         save_path (str): Đường dẫn để lưu ảnh (nếu không truyền, ảnh sẽ không được lưu).\n",
    "#         font_path (str): Đường dẫn tới file font TrueType (nếu không truyền sẽ dùng font mặc định).\n",
    "    \n",
    "#     Returns:\n",
    "#         PIL.Image.Image: Ảnh đã được vẽ bounding box.\n",
    "#     \"\"\"\n",
    "#     # Tạo bản sao ảnh để vẽ\n",
    "#     draw_image = image.copy()\n",
    "#     draw = ImageDraw.Draw(draw_image)\n",
    "    \n",
    "#     # Tải font (nếu có)\n",
    "#     if font_path:\n",
    "#         try:\n",
    "#             font = ImageFont.truetype(font_path, size=20)\n",
    "#         except Exception as e:\n",
    "#             print(f\"Không thể tải font từ {font_path}. Sử dụng font mặc định.\")\n",
    "#             font = ImageFont.load_default()\n",
    "#     else:\n",
    "#         font = ImageFont.load_default()\n",
    "    \n",
    "#     # Vẽ từng bounding box\n",
    "#     for box, label, score in zip(boxes, labels, scores):\n",
    "#         x1, y1, x2, y2 = box\n",
    "#         label_text = f\"{class_names.get(label.item(), 'Unknown')} {score:.2f}\"\n",
    "#         color = label_colors.get(label.item())\n",
    "#         # Vẽ hình chữ nhật\n",
    "#         draw.rectangle([x1, y1, x2, y2], outline=color, width=2)\n",
    "        \n",
    "#         # Vẽ nhãn với nền\n",
    "#         if hasattr(draw, \"textbbox\"):\n",
    "#             text_bbox = draw.textbbox((x1, y1), label_text, font=font)\n",
    "#             text_width, text_height = text_bbox[2] - text_bbox[0], text_bbox[3] - text_bbox[1]\n",
    "#         # else:\n",
    "#             # text_width, text_height = draw.textsize(label_text, font=font)\n",
    "#         draw.rectangle(\n",
    "#             [x1, y1 - text_height, x1 + text_width, y1],\n",
    "#             fill=color\n",
    "#         )\n",
    "#         draw.text((x1, y1 - text_height), label_text, fill=\"white\", font=font)\n",
    "    \n",
    "#     # Lưu ảnh nếu `save_path` được cung cấp\n",
    "#     if save_path:\n",
    "#         draw_image.save(save_path)\n",
    "#         # plt.imshow(draw_image)\n",
    "#         # print(f\"Ảnh đã được lưu tại: {save_path}\")\n",
    "\n",
    "\n",
    "\n",
    "# def yolo_to_xyxy(box, img_width, img_height):\n",
    "#     cx, cy, w, h = box[1:]\n",
    "#     x1 = (cx - w / 2) * img_width\n",
    "#     y1 = (cy - h / 2) * img_height\n",
    "#     x2 = (cx + w / 2) * img_width\n",
    "#     y2 = (cy + h / 2) * img_height\n",
    "#     return [x1, y1, x2, y2]\n",
    "\n",
    "# def run_inference(image, model):\n",
    "#     results = model.predict(image, verbose=False)\n",
    "#     predictions = results[0].boxes\n",
    "#     # Convert to numpy for WBF compatibility\n",
    "#     boxes = predictions.xyxy.cpu().numpy()\n",
    "#     scores = predictions.conf.cpu().numpy()\n",
    "#     labels = predictions.cls.cpu().numpy()\n",
    "#     return boxes, scores, labels\n",
    "\n",
    "# def normalize_boxes(boxes, image_size):\n",
    "#     \"\"\"Normalize box coordinates to [0, 1] range\"\"\"\n",
    "#     width, height = image_size\n",
    "#     normalized_boxes = boxes.copy()\n",
    "#     normalized_boxes[:, [0, 2]] /= width\n",
    "#     normalized_boxes[:, [1, 3]] /= height\n",
    "#     return normalized_boxes\n",
    "\n",
    "# def denormalize_boxes(boxes, image_size):\n",
    "#     \"\"\"Convert normalized boxes back to pixel coordinates\"\"\"\n",
    "#     width, height = image_size\n",
    "#     denormalized_boxes = boxes.copy()\n",
    "#     denormalized_boxes[:, [0, 2]] *= width\n",
    "#     denormalized_boxes[:, [1, 3]] *= height\n",
    "#     return denormalized_boxes\n",
    "\n",
    "# def ensemble_inference(image, method):\n",
    "#     # Get predictions from both models\n",
    "#     boxes_yolov8, scores_yolov8, labels_yolov8 = run_inference(image, yolov8)\n",
    "#     boxes_yolov9, scores_yolov9, labels_yolov9 = run_inference(image, yolov9)\n",
    "#     # print(boxes_yolov8)\n",
    "#     # Get image size\n",
    "#     if isinstance(image, torch.Tensor):\n",
    "#         height, width = image.shape[-2:]\n",
    "#     else:  # PIL Image\n",
    "#         width, height = image.size\n",
    "#     image_size = (width, height)\n",
    "#     if method in ['yolov8', 'yolov9']:\n",
    "#         if method == 'yolov8':\n",
    "#             boxes, scores, labels = boxes_yolov8, scores_yolov8, labels_yolov8\n",
    "#         else:\n",
    "#             boxes, scores, labels = boxes_yolov9, scores_yolov9, labels_yolov9\n",
    "#     else:\n",
    "#         boxes_yolov8_norm = normalize_boxes(boxes_yolov8, image_size)\n",
    "#         boxes_yolov9_norm = normalize_boxes(boxes_yolov9, image_size)\n",
    "#         boxes_list = [boxes_yolov8_norm, boxes_yolov9_norm]\n",
    "#         scores_list = [scores_yolov8, scores_yolov9]\n",
    "#         labels_list = [labels_yolov8, labels_yolov9]\n",
    "#         if len(boxes_list) == 0 or all(len(b) == 0 for b in boxes_list):\n",
    "#             # print(\"Warning: No valid boxes detected. Returning empty results.\")\n",
    "#             boxes = np.empty((0, 4), dtype=np.float32)  # Dạng bounding box\n",
    "#             scores = np.empty((0,), dtype=np.float32)  # Dạng scores\n",
    "#             labels = np.empty((0,), dtype=np.int32)\n",
    "#         else:\n",
    "#             # print(boxes_list, scores_list)\n",
    "#             if method == 'wbf':\n",
    "#                 # Apply Weighted Box Fusion\n",
    "#                 boxes, scores, labels = weighted_boxes_fusion(\n",
    "#                     boxes_list,\n",
    "#                     scores_list,\n",
    "#                     labels_list,\n",
    "#                     weights=[1, 2],  # Equal weights for both models\n",
    "#                     iou_thr=0.5,\n",
    "#                     skip_box_thr=0.0001,\n",
    "#                 )\n",
    "#             elif method == 'nms':\n",
    "#                 boxes, scores, labels = nms(\n",
    "#                     boxes_list,\n",
    "#                     scores_list,\n",
    "#                     labels_list,\n",
    "#                     weights=[1, 2],  # Equal weights for both models\n",
    "#                     iou_thr=0.5\n",
    "#                 )\n",
    "#                 # print(type(boxes), '\\n', type(scores), '\\n',type(labels))\n",
    "#             elif method == 'soft_nms':\n",
    "#                 boxes, scores, labels = soft_nms(\n",
    "#                     boxes_list,\n",
    "#                     scores_list,\n",
    "#                     labels_list,\n",
    "#                     weights=[1, 2],  # Equal weights for both models\n",
    "#                     iou_thr=0.5,\n",
    "#                     sigma = 0.1,\n",
    "#                     thresh = 0.0001\n",
    "#                 )\n",
    "#             else:\n",
    "#                 boxes, scores, labels = non_maximum_weighted(\n",
    "#                     boxes_list,\n",
    "#                     scores_list,\n",
    "#                     labels_list,\n",
    "#                     weights=[1, 2],  # Equal weights for both models\n",
    "#                     iou_thr=0.5,\n",
    "#                     skip_box_thr=0.0001,\n",
    "#                 )\n",
    "#             boxes = denormalize_boxes(boxes, image_size)\n",
    "#     # Convert back to torch tensors\n",
    "#     boxes = torch.from_numpy(boxes).float()\n",
    "#     scores = torch.from_numpy(scores).float()\n",
    "#     labels = torch.from_numpy(labels).long()\n",
    "#     return boxes, scores, labels\n",
    "\n",
    "# def read_label_file(label_path, img_width, img_height):\n",
    "#     boxes = []\n",
    "#     labels = []\n",
    "#     with open(label_path, \"r\") as f:\n",
    "#         for line in f:\n",
    "#             box = list(map(float, line.strip().split()))\n",
    "#             labels.append(int(box[0]))\n",
    "#             boxes.append(yolo_to_xyxy(box, img_width, img_height))\n",
    "#     return boxes, labels\n",
    "\n",
    "# # Main validation loop\n",
    "# # for sub in ['LR', 'Bicubic', 'SRCNN', 'VDSR', 'SRResNet', 'EDSR', 'HQSR_S', 'HQSR_C', 'HR']:\n",
    "# # for sub in ['Bicubic']:\n",
    "# # for sub in ['SRCNN', 'VDSR', 'SRResNet', 'EDSR', 'HQSR_S', 'HQSR_C', 'HR']:\n",
    "# # for sub in ['test_150', 'test_150_ESR_Canny','test_150_ESR_Sobel','test_600']:\n",
    "# # for quality in [10, 20, 40, 80]:\n",
    "# # for quality in [10, 20, 30, 40]:\n",
    "# # for quality in [20, 40, 80]:\n",
    "\n",
    "# for quality in test_quality:\n",
    "\n",
    "#     # for sub in ['','_ISR','_IQE', '_ISR + IQE', '_IQE + ISR', '_IQE + ISR + IQE', 'full']:\n",
    "#     # for sub in ['','_ISR', '_IQE', '_ISR + IQE', '_IQE + ISR', 'full']:\n",
    "#     # for sub in ['_IQE + ISR + IQE' ]:\n",
    "#     # for sub in ['','_ISR' ]:\n",
    "#     for sub in detect_subs:\n",
    "#         # Tạo thư mục gốc cho inference\n",
    "#         base_output_dir = \"runs\"\n",
    "#         os.makedirs(base_output_dir, exist_ok=True)\n",
    "#         path = f'output/test_{quality}_150{sub}'\n",
    "#         # path = 'output/test_600'\n",
    "\n",
    "#         if sub == 'full':\n",
    "#             path = f'output/test_{quality}_600' \n",
    "#         data = {\n",
    "#             'train': f'/kaggle/input/tesstt/images',\n",
    "#             'val': f'{path}/images',\n",
    "#             'nc': 6,\n",
    "#             'names': {\n",
    "#                 0: 'mouse_bite',\n",
    "#                 1: 'spur',\n",
    "#                 2: 'missing_hole',\n",
    "#                 3: 'short',\n",
    "#                 4: 'open_circuit',\n",
    "#                 5: 'spurious_copper'\n",
    "#             }\n",
    "#         }\n",
    "        \n",
    "#         with open('output/data.yaml', 'w') as file:\n",
    "#             yaml.dump(data, file, default_flow_style=False)\n",
    "    \n",
    "#         print(f\"Evaluating {sub} dataset at QF {quality}...\")\n",
    "#         # # Run individual model validation\n",
    "#         # results1 = yolov8.val(data='output/data.yaml', batch=1)\n",
    "#         # results2 = yolov9.val(data='output/data.yaml', batch=1)\n",
    "    \n",
    "#         # path = f'output/test_{quality}_150{sub}'\n",
    "#         # path = '/kaggle/input/test600/test1_600x600'\n",
    "#         images_dir = f\"{path}/images\"\n",
    "#         labels_dir = f\"{path}/labels\"\n",
    "#         # Initialize Mean Average Precision metric\n",
    "#         map_metric = MeanAveragePrecision(iou_thresholds=[0.5], iou_type=\"bbox\", class_metrics=True)\n",
    "        \n",
    "#         # for method in ['yolov8', 'yolov9',  'nms', 'soft_nms','nmw','wbf']:\n",
    "#         for method in ['yolov8']:\n",
    "#             map_metric.reset()\n",
    "#             print(f\"Running {method} inference with on {sub}...\")\n",
    "#             # Tạo thư mục riêng cho từng phương pháp\n",
    "#             method_output_dir = os.path.join(base_output_dir, method, sub)\n",
    "#             os.makedirs(method_output_dir, exist_ok=True)\n",
    "    \n",
    "#             for image_file in tqdm(os.listdir(images_dir), unit='img'):\n",
    "#                 img_path = os.path.join(images_dir, image_file)\n",
    "#                 image = Image.open(img_path).convert('RGB')\n",
    "#                 # Get true labels\n",
    "#                 label_path = os.path.join(labels_dir, image_file[:-4] + \".txt\")\n",
    "#                 true_boxes, true_labels = read_label_file(label_path, image.size[0], image.size[1])\n",
    "#                 true_boxes = torch.tensor(true_boxes, dtype=torch.float32)\n",
    "#                 true_labels = torch.tensor(true_labels, dtype=torch.int64)\n",
    "    \n",
    "#                 # Chạy inference theo phương pháp\n",
    "#                 pred_boxes, pred_scores, pred_labels = ensemble_inference(image, method)\n",
    "    \n",
    "#                 # Format predictions and targets for metric update\n",
    "#                 predictions = [{\n",
    "#                     'boxes': pred_boxes,\n",
    "#                     'scores': pred_scores,\n",
    "#                     'labels': pred_labels\n",
    "#                 }]\n",
    "                \n",
    "#                 targets = [{\n",
    "#                     'boxes': true_boxes,\n",
    "#                     'labels': true_labels\n",
    "#                 }]\n",
    "#                 # print(predictions,'\\n', targets)\n",
    "#                 map_metric.update(predictions, targets)\n",
    "    \n",
    "#                 # Vẽ và lưu ảnh\n",
    "#                 # flag = bool(random.randint(0, 1))\n",
    "#                 # if flag:\n",
    "#                 save_path = os.path.join(method_output_dir, image_file)  # Lưu với cùng tên ảnh\n",
    "#                 draw_and_save_predictions(\n",
    "#                     image=image.copy(),\n",
    "#                     boxes=pred_boxes.numpy(),\n",
    "#                     labels=pred_labels.numpy(),\n",
    "#                     scores=pred_scores.numpy(),\n",
    "#                     class_names=data['names'],\n",
    "#                     save_path=save_path\n",
    "#                 )\n",
    "    \n",
    "#             # Tính toán kết quả sau khi xử lý tất cả ảnh\n",
    "#             results = map_metric.compute()\n",
    "#             print(f\"\\nResults for {method} on {sub}:\")\n",
    "#             map50_per_class = results['map_per_class']\n",
    "#             for class_idx, map_value in enumerate(map50_per_class):\n",
    "#                 print(f\"Class {class_idx}: mAP@50 = {map_value.item():.3f}\")\n",
    "#             print(results['map'])\n",
    "#             print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
