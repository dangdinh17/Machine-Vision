dataset:
  train:  # LMDB
    type: PCB_dataset

    # for dataset
    hr_train: ./dataset/40_e2e/train/HQ
    lr_train: ./dataset/40_e2e/train/LQ
    label_train: ./dataset/40_e2e/train/labels

    hr_val: ./dataset/40_e2e/test/HQ
    lr_val: ./dataset/40_e2e/test/LQ
    label_val: ./dataset/40_e2e/test/labels

    meta_info_fp: log/log.txt

    imgsz: 128 # ground truth patch size: gt_size * gt_size
    augment: True
    scale: 4

    # for datasampler
    enlarge_ratio: 300  # enlarge dataset by randomly cropping.

    # for dataloader   Defined in utils/deep_learning.py
    num_worker_per_gpu: 8  # 12 in total. mainly affect IO
    batch_size_per_gpu: 1  # bs=8, divided by 1 GPUs

comet_logging:
  using: False
  previous_experiment: False
  api_key: mkfmxVIjacb8h74qKO6NzPdPN # your comet api key
  project_name: cisr-project
  workspace: dangdinh17


network:
  iqe_type: Enhancer_Small
  isr_type: ESR
  detection: YOLOv8

train:
  num_gpu: 1
  exp_name: Enhancer_Small_e2e_FPNLoss # default: timestr. None: ~
  random_seed: 7
  num_iter: 200000
  interval_train:  1
  load_path: None
  load_detection: exp/Enhancer_Small_e2e_64/ckp_19_detection.pth
  best_iqe_model: exp/Enhancer_Small_ISRout_64/best_weight.pth
  best_isr_model: exp/weights/best_esr_40.pth
  best_detection_model: exp/weights/bestyolov8.pt
  best_backbone: exp/FasterRCNN_ResNet18_PCB/best_backbone_49.pth
  alpha: 0.8
  num_classes: 6
  name_classes:
    0: mouse_bite
    1: spur
    2: missing_hole
    3: short
    4: open_circuit
    5: spurious_copper
    # - mouse_bite
    # - spur
    # - missing_hole
    # - short
    # - open_circuit
    # - spurious_copper
  optim:
    type: Adam
    lr: !!float 1e-5  #  #  1e-4  5e-5  # init lr of scheduler
    betas: [0.9, 0.999]
    eps: !!float 1e-08

  scheduler:
    is_on: True
    type: CosineAnnealingRestartLR
    periods: [!!float 5e+4, !!float 5e+4, !!float 5e+4, !!float 5e+4, !!float 5e+4, !!float 5e+4]  # epoch interval
    restart_weights: [1, 0.5, 0.5, 0.5, 0.5, 0.5]
    eta_min: !!float 1e-7

  detection_scheduler:
      periods: [!!float 5e+4, !!float 5e+4, !!float 5e+4, !!float 5e+4, !!float 5e+4, !!float 5e+4]  # epoch interval
      restart_weights: [1, 0.5, 0.5, 0.5, 0.5, 0.5]
      eta_min: !!float 1e-5

  detection_optim:
    type: SGD
    lr: !!float 0.0005  #  #  1e-4  5e-5  # init lr of scheduler
    momentum: 0.937
    nesterov: True
    weight_decay: 5e-4

  loss:  # Defined in utils/deep_learning.py
    #type: CharbonnierLoss
    eps: !!float 1e-6
    type: CharbonnierLoss


  criterion: # Defined in utils/deep_learning.py
    type: PSNR
    unit: dB


