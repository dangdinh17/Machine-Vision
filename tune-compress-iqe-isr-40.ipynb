{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2025-08-12T14:36:19.205622Z","iopub.status.busy":"2025-08-12T14:36:19.205257Z","iopub.status.idle":"2025-08-12T14:36:26.960244Z","shell.execute_reply":"2025-08-12T14:36:26.959165Z","shell.execute_reply.started":"2025-08-12T14:36:19.205586Z"},"trusted":true},"outputs":[],"source":["!pip install comet_ml"]},{"cell_type":"markdown","metadata":{},"source":["# 1. Import thư viện"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["2\n","1\n"]}],"source":["import random\n","\n","random.seed(42)\n","print(random.randint(1, 10))  # Lần nào cũng ra 2\n","print(random.randint(1, 10))  # Lần nào cũng ra 1\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2025-08-12T14:37:06.179876Z","iopub.status.busy":"2025-08-12T14:37:06.179577Z","iopub.status.idle":"2025-08-12T14:37:07.956801Z","shell.execute_reply":"2025-08-12T14:37:07.956087Z","shell.execute_reply.started":"2025-08-12T14:37:06.179855Z"},"trusted":true},"outputs":[],"source":["from comet_ml import Experiment, ExistingExperiment\n","\n","# Khởi tạo Comet\n","quality = 40\n","patch = 1\n","imgsz = 128\n","batch_size = 8\n","isr_output = True\n","\n","if imgsz == 128 and isr_output == True:\n","    previous_key = '4f97aded96b7428b9c462cbd636b17a6'\n","    weight_path = f'/kaggle/input/tamsadsadas/best_iqe_40_{imgsz}_isr_output.pth'\n","elif imgsz == 64 and isr_output == True:\n","    previous_key = '3bdcae67caa24c2d89dca167aef9cbde'\n","    weight_path = f'/kaggle/input/tamsadsadas/best_iqe_40_{imgsz}_isr_output.pth'\n","experiment = ExistingExperiment(\n","    previous_experiment = previous_key,\n","    api_key=\"mkfmxVIjacb8h74qKO6NzPdPN\",\n","    project_name=\"cisr-project\",\n","    workspace=\"dangdinh17\"          # Tên workspace trên Comet\n",")\n","\n","\n","experiment.set_name(f\"Final IQE + ISR Training Run at size of {imgsz}\")\n","# "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2025-08-12T14:37:09.251091Z","iopub.status.busy":"2025-08-12T14:37:09.250774Z","iopub.status.idle":"2025-08-12T14:37:09.257213Z","shell.execute_reply":"2025-08-12T14:37:09.256285Z","shell.execute_reply.started":"2025-08-12T14:37:09.251061Z"},"trusted":true},"outputs":[],"source":["import cv2\n","import numpy as np\n","import os\n","from PIL import Image\n","import shutil\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.optim as optim\n","from torchvision import transforms\n","import torchsummary\n","from torch.utils.data import DataLoader, Dataset\n","from torch.nn.parallel import DataParallel\n","from torch.cuda.amp import autocast, GradScaler\n","import torch.nn.functional as F\n","from torchvision.utils import save_image\n","\n","from tqdm import tqdm\n","import sys\n","sys.path.append('/kaggle/input/full/pytorch/default/3')\n","from e2dsr import *\n","from vdsr import *\n","\n","from hqsr import *\n","from vdsr import *\n","from srresnet import *\n","from sr_model import *\n","from vdsr import *\n","from utils import *\n","from srcnn import *\n","from edsr import *\n","from iqe import *\n","from network_swinir import *\n","import time\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","import random"]},{"cell_type":"markdown","metadata":{},"source":["# Tạo data"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2025-08-12T09:20:59.752329Z","iopub.status.busy":"2025-08-12T09:20:59.752037Z","iopub.status.idle":"2025-08-12T09:20:59.756403Z","shell.execute_reply":"2025-08-12T09:20:59.755579Z","shell.execute_reply.started":"2025-08-12T09:20:59.752308Z"},"trusted":true},"outputs":[],"source":["import os\n","os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:128'\n","os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cuda')\n","max_training_time = 11 * 3600 +  50 * 60  # 11 giờ 50 phút tính bằng giây\n","start_training_time = time.time()  # Ghi lại thời gian bắt đầu\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2025-08-12T09:20:59.757421Z","iopub.status.busy":"2025-08-12T09:20:59.757160Z","iopub.status.idle":"2025-08-12T09:21:01.276645Z","shell.execute_reply":"2025-08-12T09:21:01.275746Z","shell.execute_reply.started":"2025-08-12T09:20:59.757401Z"},"trusted":true},"outputs":[],"source":["# img_dir = '/kaggle/input/div2k/DIV2K/HR'\n","img_dir = '/kaggle/input/test600/test1_600x600/images'\n","\n","# for quality in [20]:\n","types = 'test'\n","# output = f'compress/quality_compress_{quality}'\n","output_lr = f'dataset/{types}/LQ'\n","output_hr = f'dataset/{types}/HQ'\n","os.makedirs(output_lr, exist_ok = True)\n","os.makedirs(output_hr, exist_ok = True)\n","# os.makedirs(output, exist_ok = True)\n","for path in tqdm(os.listdir(img_dir)[:100], desc = f'quality {quality}', unit = 'img'):\n","    img_path = os.path.join(img_dir, path)\n","    # out_path = os.path.join(output, f\"{os.path.splitext(path)[0]}.png\")\n","    out_lr_path = os.path.join(output_lr, f\"{os.path.splitext(path)[0]}_{quality}.png\")\n","    out_hr_path = os.path.join(output_hr, f\"{os.path.splitext(path)[0]}_{quality}.png\")\n","    img = Image.open(img_path)\n","    h, w = img.size\n","    # print(h, w)\n","    out = img.resize((h//4, w//4))\n","    # out = img\n","    if quality == 'origin':\n","        out.save(out_lr_path, format=\"PNG\", optimize=True)\n","        \n","    else:\n","        out.save(out_lr_path, format=\"JPEG\", quality=quality, optimize=True)\n","    # img.save(out_hr_path, format='PNG', quality=100, optimize=True)\n","    shutil.copy2(img_path, out_hr_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2025-08-12T09:21:01.277961Z","iopub.status.busy":"2025-08-12T09:21:01.277653Z","iopub.status.idle":"2025-08-12T09:22:43.163358Z","shell.execute_reply":"2025-08-12T09:22:43.162618Z","shell.execute_reply.started":"2025-08-12T09:21:01.277930Z"},"trusted":true},"outputs":[],"source":["for types in ['train']:\n","    # img_dir = f'/kaggle/input/div2k-dataset/DIV2K_{types}_HR/DIV2K_{types}_HR'\n","    img_dir = f'/kaggle/input/train600/train/images'\n","    # for quality in [20, 'origin']:\n","    # for quality in [20]:\n","\n","    output_lr = f'dataset/{types}/LQ'\n","    output_hr = f'dataset/{types}/HQ'\n","    os.makedirs(output_lr, exist_ok = True)\n","    os.makedirs(output_hr, exist_ok = True)\n","    for _, path in enumerate(tqdm(os.listdir(img_dir)[:int(len(os.listdir(img_dir)))], desc = f'quality {quality}', unit = 'img')):\n","        img_path = os.path.join(img_dir, path)\n","        # out_lr_path = os.path.join(output_lr, f\"{os.path.splitext(path)[0]}_{quality}.png\")\n","        # out_hr_path = os.path.join(output_hr, f\"{os.path.splitext(path)[0]}_{quality}.png\")\n","        # if i > 1:\n","            # continue\n","        if types == 'train' and quality != 'origin':\n","            patches = 1\n","        else:\n","            patches = 1\n","        for i in range(patches):\n","            out_lr_path = os.path.join(output_lr, f\"{os.path.splitext(path)[0]}_{quality}_{i}.png\")\n","            out_hr_path = os.path.join(output_hr, f\"{os.path.splitext(path)[0]}_{quality}_{i}.png\")\n","            img = Image.open(img_path)\n","            h, w = img.size  \n","            size = imgsz\n","            # print(f\"Current types: {types}\")\n","            # if types == 'train':\n","            # # Xác định tọa độ cắt ngẫu nhiên\n","            #     x = random.randint(0, w - size)\n","            #     y = random.randint(0, h - size)\n","                \n","            #     # Cắt vùng ảnh 196x196\n","            #     img = img.crop((x, y, x + size, y + size))\n","                \n","            # h, w = img.size \n","            # print(img.size, out.size)\n","            out = img.resize((h//4, w//4))\n","\n","            # out = img\n","            if quality == 'origin':\n","                out.save(out_lr_path, format=\"PNG\", optimize=True)\n","                \n","            else:\n","                out.save(out_lr_path, format=\"JPEG\", quality=quality, optimize=True)\n","            # img.save(out_hr_path, format='PNG', quality=100, optimize=True)\n","            shutil.copy2(img_path, out_hr_path)\n","           "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2025-08-12T09:22:43.164369Z","iopub.status.busy":"2025-08-12T09:22:43.164121Z","iopub.status.idle":"2025-08-12T09:22:43.167880Z","shell.execute_reply":"2025-08-12T09:22:43.167074Z","shell.execute_reply.started":"2025-08-12T09:22:43.164347Z"},"trusted":true},"outputs":[],"source":["# import shutil\n","# for types in ['train', 'test']:\n","#     for qual in ['LQ', 'HQ']:\n","#         if qual == 'LQ':\n","#             img_dir = f'/kaggle/input/sr-dataset/_output_/dataset/{quality}/{types}/{qual}'\n","#         else:\n","#             img_dir = f'/kaggle/input/sr-dataset/_output_/dataset/{types}/{qual}'\n","        \n","#         hr_img_path = f'dataset/{types}/{qual}'\n","        \n","#         os.makedirs(hr_img_path, exist_ok = True)\n","        \n","#         for path in tqdm(os.listdir(img_dir), unit = 'img'):\n","#             source_file = os.path.join(img_dir, path)\n","#             file1 = os.path.join(hr_img_path, path)\n","#             shutil.copy(source_file, file1)\n","           "]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2025-08-12T09:22:43.170154Z","iopub.status.busy":"2025-08-12T09:22:43.169956Z","iopub.status.idle":"2025-08-12T09:22:43.183868Z","shell.execute_reply":"2025-08-12T09:22:43.183244Z","shell.execute_reply.started":"2025-08-12T09:22:43.170137Z"},"trusted":true},"outputs":[],"source":["# import shutil\n","# shutil.make_archive('dataset', 'zip', 'dataset')"]},{"cell_type":"markdown","metadata":{},"source":["# 2. Tạo Mô hình SR"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2025-08-12T09:22:43.185612Z","iopub.status.busy":"2025-08-12T09:22:43.185372Z","iopub.status.idle":"2025-08-12T09:22:43.201870Z","shell.execute_reply":"2025-08-12T09:22:43.201252Z","shell.execute_reply.started":"2025-08-12T09:22:43.185593Z"},"trusted":true},"outputs":[],"source":["import torchvision.transforms.functional as TF\n","\n","class ImageDataset(Dataset):\n","    def __init__(self, lr_dir, hr_dir, scale, valid = False):\n","        self.lr_files = sorted(os.listdir(lr_dir))\n","        self.hr_files = sorted(os.listdir(hr_dir))\n","        self.lr_dir = lr_dir\n","        self.hr_dir = hr_dir\n","        self.scale = scale\n","        self.valid = valid\n","\n","    def __len__(self):\n","        return len(self.lr_files)\n","\n","    def __getitem__(self, idx):\n","        lr_image = Image.open(os.path.join(self.lr_dir, self.lr_files[idx])).convert('RGB')\n","        hr_image = Image.open(os.path.join(self.hr_dir, self.hr_files[idx])).convert('RGB')\n","    \n","        w, h= hr_image.size\n","        # print(hr_image.size, lr_image.size)\n","        # if self.valid:\n","            # lr_image = lr_image.resize((w//self.scale, h//self.scale))\n","        transform = transforms.Compose([\n","            transforms.ToTensor()\n","        ])\n","\n","        if self.valid:\n","            def transform_fn(lr_img, hr_img):\n","                # i, j, h, w = transforms.RandomCrop.get_params(lr_img, output_size=(imgsz, imgsz))\n","                # lr_img = TF.crop(lr_img, i, j, h, w)\n","                # hr_img = TF.crop(hr_img, i, j, h, w)\n","                lr_img = TF.to_tensor(lr_img)\n","                hr_img = TF.to_tensor(hr_img)\n","        \n","                return lr_img, hr_img\n","\n","        else:\n","            def transform_fn(lr_img, hr_img):\n","                # Lấy thông số ngẫu nhiên cho cropping\n","                i, j, h, w = transforms.RandomCrop.get_params(lr_img, output_size=(imgsz//4, imgsz//4))\n","                lr_img = TF.crop(lr_img, i, j, h, w)\n","                hr_img = TF.crop(hr_img, i * scale, j * scale, h * scale, w * scale)\n","        \n","                # Áp dụng cùng một phép xoay ngẫu nhiên\n","                angle = random.uniform(-30, 30)\n","                lr_img = TF.rotate(lr_img, angle)\n","                hr_img = TF.rotate(hr_img, angle)\n","        \n","                # Áp dụng cùng một phép lật ngang\n","                if random.random() > 0.5:\n","                    lr_img = TF.hflip(lr_img)\n","                    hr_img = TF.hflip(hr_img)\n","        \n","                # Áp dụng cùng một phép lật dọc\n","                if random.random() > 0.5:\n","                    lr_img = TF.vflip(lr_img)\n","                    hr_img = TF.vflip(hr_img)\n","        \n","                # Chuyển sang tensor\n","                lr_img = TF.to_tensor(lr_img)\n","                hr_img = TF.to_tensor(hr_img)\n","        \n","                return lr_img, hr_img\n","        lr_image, hr_image = transform_fn(lr_image, hr_image)\n","        return lr_image, hr_image\n","        "]},{"cell_type":"markdown","metadata":{},"source":["# 3. Tạo Hyperparameter"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2025-08-12T14:37:14.586058Z","iopub.status.busy":"2025-08-12T14:37:14.585756Z","iopub.status.idle":"2025-08-12T14:37:14.636191Z","shell.execute_reply":"2025-08-12T14:37:14.635488Z","shell.execute_reply.started":"2025-08-12T14:37:14.586032Z"},"trusted":true},"outputs":[],"source":["iqe = IQE().to(device)\n","isr = HQSR(scale_factor=4, use_canny=True).to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2025-08-12T14:37:33.361408Z","iopub.status.busy":"2025-08-12T14:37:33.361092Z","iopub.status.idle":"2025-08-12T14:37:33.955199Z","shell.execute_reply":"2025-08-12T14:37:33.954531Z","shell.execute_reply.started":"2025-08-12T14:37:33.361380Z"},"trusted":true},"outputs":[],"source":["weight_isr = f'/kaggle/input/tamsadsadas/checkpoint_isr_{imgsz}.pth'\n","weight_iqe = f'/kaggle/input/tamsadsadas/checkpoint_iqe_{imgsz}.pth'\n","\n","isr.load_state_dict(torch.load(weight_isr, map_location=device)['model_state_dict'])\n","iqe.load_state_dict(torch.load(weight_iqe, map_location=device)['model_state_dict'])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2025-08-12T14:37:35.271305Z","iopub.status.busy":"2025-08-12T14:37:35.271004Z","iopub.status.idle":"2025-08-12T14:37:35.274860Z","shell.execute_reply":"2025-08-12T14:37:35.274026Z","shell.execute_reply.started":"2025-08-12T14:37:35.271279Z"},"trusted":true},"outputs":[],"source":["import os\n","os.environ[\"TORCH_USE_CUDA_DSA\"] = \"1\"\n","os.environ[\"CUDA_LAUNCH_BLOCKING\"]=\"1\""]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2025-08-12T14:37:35.570081Z","iopub.status.busy":"2025-08-12T14:37:35.569802Z","iopub.status.idle":"2025-08-12T14:37:35.574293Z","shell.execute_reply":"2025-08-12T14:37:35.573425Z","shell.execute_reply.started":"2025-08-12T14:37:35.570058Z"},"trusted":true},"outputs":[],"source":["def calculate_psnr(img1, img2):\n","    mse = torch.mean((img1 - img2) ** 2)\n","    if mse == 0:\n","        return float('inf')\n","    max_pixel = 1.0\n","    psnr = 20 * torch.log10(max_pixel / torch.sqrt(mse))\n","    return psnr.item()"]},{"cell_type":"markdown","metadata":{},"source":["# 4. Training"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2025-08-12T14:37:36.640746Z","iopub.status.busy":"2025-08-12T14:37:36.640420Z","iopub.status.idle":"2025-08-12T14:37:36.647046Z","shell.execute_reply":"2025-08-12T14:37:36.646082Z","shell.execute_reply.started":"2025-08-12T14:37:36.640719Z"},"trusted":true},"outputs":[],"source":["def save_checkpoint(model, optimizer, scheduler, epoch, train_step, test_step, best_loss, path=\"checkpoint.pth\"):\n","    checkpoint = {\n","        'model_state_dict': model.state_dict(),\n","        'optimizer_state_dict': optimizer.state_dict(),\n","        'scheduler_state_dict': scheduler.state_dict(),\n","        'epoch': epoch,\n","        'train_step': train_step,\n","        'test_step':test_step,\n","        'best_loss': best_loss,\n","    }\n","    torch.save(checkpoint, path)\n","    print(f\"Checkpoint saved at {path}\")\n","\n","# Hàm tải trạng thái\n","def load_checkpoint(model, optimizer, scheduler, path=\"checkpoint.pth\"):\n","    if os.path.isfile(path):\n","        checkpoint = torch.load(path)\n","        model.load_state_dict(checkpoint['model_state_dict'])\n","        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n","        scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n","        epoch = checkpoint['epoch']\n","        train_step = checkpoint['train_step']\n","        val_step = checkpoint['test_step']\n","        best_loss = checkpoint['best_loss']\n","        print(f\"Checkpoint loaded from {path}\")\n","    else:\n","        print(f\"No checkpoint found at {path}\")\n","        epoch, train_step, val_step, best_loss = 0, 0, 0, float('inf')\n","    return epoch, train_step, val_step, best_loss\n","\n","def load_model_state(model, checkpoint_path=\"checkpoint.pth\"):\n","    checkpoint = torch.load(checkpoint_path)\n","    model.load_state_dict(checkpoint['model_state_dict'])\n","    print(f\"Model state loaded from {checkpoint_path}\")\n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2025-08-12T14:37:39.784388Z","iopub.status.busy":"2025-08-12T14:37:39.783992Z","iopub.status.idle":"2025-08-12T14:37:39.796409Z","shell.execute_reply":"2025-08-12T14:37:39.795509Z","shell.execute_reply.started":"2025-08-12T14:37:39.784348Z"},"trusted":true},"outputs":[],"source":["from torch.amp import autocast, GradScaler\n","from torchsummary import summary\n","scaler = GradScaler()\n","\n","# Khởi tạo dataset và dataloader\n","# for scale in [2, 3, 4]:\n","scale = 4\n","num_iterations= 3e5\n","train_lr_dir = f'dataset/train/LQ'\n","train_hr_dir = 'dataset/train/HQ'\n","# valid_lr_dir = 'dataset/valid/LQ'\n","# valid_hr_dir = 'dataset/valid/HQ'\n","\n","valid_lr_dir = 'dataset/test/LQ'\n","valid_hr_dir = 'dataset/test/HQ'\n","test_lr_dir = 'dataset/test/LQ'\n","test_hr_dir = 'dataset/test/HQ'\n","\n","train_dataset = ImageDataset(train_lr_dir, train_hr_dir, scale=scale)\n","train_loader = DataLoader(train_dataset, batch_size = batch_size, shuffle=True)\n","\n","valid_dataset = ImageDataset(valid_lr_dir, valid_hr_dir, scale=scale, valid=True)\n","valid_loader = DataLoader(valid_dataset)\n","\n","test_dataset = ImageDataset(test_lr_dir, test_hr_dir, scale=scale, valid=True)\n","test_loader = DataLoader(test_dataset)\n","# print(len(train_loader))\n","# Khởi tạo mô hình, loss function và optimizer\n","torch.cuda.empty_cache()\n","\n","criterion = nn.MSELoss()\n","optim_iqe = optim.Adam(list(isr.parameters()) + list(iqe.parameters()), lr=1e-5,betas =(0.9, 0.999))\n","scheduler = optim.lr_scheduler.StepLR(optim_iqe, step_size=10**5, gamma=0.5)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2025-08-12T14:38:01.071873Z","iopub.status.busy":"2025-08-12T14:38:01.071554Z","iopub.status.idle":"2025-08-12T14:38:01.210071Z","shell.execute_reply":"2025-08-12T14:38:01.208929Z","shell.execute_reply.started":"2025-08-12T14:38:01.071846Z"},"trusted":true},"outputs":[],"source":["os.makedirs('outputs/weight', exist_ok=True)\n","os.makedirs('outputs/path', exist_ok=True)\n","\n","best_loss= float('inf')\n","\n","torch.cuda.empty_cache()\n","\n","train_loss = []\n","val_loss = []\n","\n","train_psnr = []\n","val_psnr = []\n","\n","log_file = open('iqe.txt', 'a')\n","\n","start_epoch, train_step, val_step, best_loss = 0, 0, 0, float('inf')\n","start_epoch, train_step, val_step, best_loss = load_checkpoint(iqe, optim_iqe, scheduler, path=weight_iqe)\n","# model = load_model_state(\n","#     model,  checkpoint_path=\"/kaggle/input/lolv1w/reslle.pth\"\n","# )\n","patience = 80\n","epochs_no_improve = 0\n","\n","num_epochs = math.ceil(num_iterations / len(train_loader))\n","# num_epochs = 5"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2025-08-12T09:22:44.130080Z","iopub.status.busy":"2025-08-12T09:22:44.129855Z","iopub.status.idle":"2025-08-12T09:22:44.143741Z","shell.execute_reply":"2025-08-12T09:22:44.143036Z","shell.execute_reply.started":"2025-08-12T09:22:44.130051Z"},"trusted":true},"outputs":[],"source":["def tensor_batch_to_pil(tensor):    \n","    if isinstance(tensor, torch.Tensor):\n","        output_image = tensor.squeeze(0).cpu()  # Loại bỏ batch dimension và chuyển tensor sang CPU\n","        output_image = transforms.ToPILImage()(output_image)  # Chuyển tensor thành ảnh PIL\n","\n","    elif isinstance(tensor, Image.Image):\n","        output_image = tensor\n","    return output_image"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2025-08-12T09:22:44.144744Z","iopub.status.busy":"2025-08-12T09:22:44.144512Z","iopub.status.idle":"2025-08-12T09:22:44.161351Z","shell.execute_reply":"2025-08-12T09:22:44.160513Z","shell.execute_reply.started":"2025-08-12T09:22:44.144722Z"},"trusted":true},"outputs":[],"source":["def concat_triplet_batch(lr, isr_out, iqe_out, out):\n","    # for i in range(lr.size(0)):\n","    lr_img = tensor_batch_to_pil(lr)\n","    isr_img = tensor_batch_to_pil(isr_out)\n","    iqe_img = tensor_batch_to_pil(iqe_out)\n","    out_img = tensor_batch_to_pil(out)\n","    w, h = lr_img.size\n","    combined = Image.new(\"RGB\", (w*13, h*4))\n","    combined.paste(lr_img, (0,0))\n","    combined.paste(isr_img, (w,0))\n","    combined.paste(iqe_img, (5*w,0))\n","    combined.paste(out_img, (9*w,0))\n","    return combined\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2025-08-12T09:22:44.162434Z","iopub.status.busy":"2025-08-12T09:22:44.162175Z","iopub.status.idle":"2025-08-12T09:22:44.175976Z","shell.execute_reply":"2025-08-12T09:22:44.175180Z","shell.execute_reply.started":"2025-08-12T09:22:44.162415Z"},"trusted":true},"outputs":[],"source":["torch.cuda.empty_cache()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"execution_failed":"2025-08-12T09:23:54.076Z","iopub.execute_input":"2025-08-12T09:22:44.177184Z","iopub.status.busy":"2025-08-12T09:22:44.176907Z"},"trusted":true},"outputs":[],"source":["for epoch in range(start_epoch, num_epochs):\n","    iqe.train()\n","    isr.train()\n","    epoch_loss, epoch_psnr = 0, 0\n","    \n","    start_time = time.time()\n","    torch.cuda.empty_cache()\n","    # Training loop for each model\n","    for i, (lr_images, hr_images) in enumerate(tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs}', unit='batch')):\n","        lr_images = lr_images.to(device)\n","        hr_images = hr_images.to(device)\n","        # print(lr_images.shape)\n","\n","        # # Train model model\n","        optim_iqe.zero_grad()\n","        with autocast(device_type='cuda'):\n","            output_sr = isr(lr_images)\n","            outputs = iqe(output_sr)\n","            loss_sr = criterion(output_sr, hr_images)\n","            loss_iqe = criterion(outputs, hr_images)\n","            loss = 0.5 * loss_sr + 0.5 * loss_iqe\n","            # if epoch % 25  == 0 and i == 0:\n","            #     experiment.log_image(tensor_batch_to_pil(hr_images), name=f\"HR_image\", step=epoch)\n","            #     experiment.log_image(tensor_batch_to_pil(output_sr), name=f\"ISR output\", step=epoch)\n","            #     experiment.log_image(tensor_batch_to_pil(outputs), name=f\"IQE output\", step=epoch)\n","\n","\n","        psnr = calculate_psnr(outputs, hr_images)\n","\n","        scaler.scale(loss).backward()\n","        scaler.step(optim_iqe)\n","        scaler.update()\n","        scheduler.step()\n","\n","        epoch_loss += loss.item()\n","        epoch_psnr += psnr\n","        \n","        train_step += 1\n","        elapsed_time = time.time() - start_training_time\n","        \n","        experiment.log_metric(\"train_loss\", loss.item(), step=train_step)\n","        experiment.log_metric(\"train_psnr\", psnr, step=train_step)\n","\n","    # Average losses and PSNRs\n","    avg_epoch_loss = epoch_loss / len(train_loader)\n","    avg_epoch_psnr = epoch_psnr / len(train_loader)\n","\n","\n","    # Validation for all models\n","    iqe.eval()\n","    isr.eval()\n","    epoch_val_psnr = 0\n","    epoch_val_loss = 0\n","    with torch.no_grad():\n","        for i, (lr_images, hr_images) in enumerate(tqdm(valid_loader, desc=f'Val Epoch {epoch+1}: ', unit='batch')):\n","            lr_images = lr_images.cuda()\n","            hr_images = hr_images.cuda()\n","\n","            # # Validate model\n","            output_sr = isr(lr_images)\n","            outputs = iqe(output_sr)\n","            loss_sr = criterion(output_sr, hr_images)\n","            loss_iqe = criterion(outputs, hr_images)\n","            loss = 0.5 * loss_sr + 0.5 * loss_iqe\n","            \n","            psnr = calculate_psnr(outputs, hr_images)\n","            epoch_val_loss += loss.item()\n","            epoch_val_psnr += psnr\n","            experiment.log_metric(\"val_loss\", loss.item(), step=val_step)\n","            experiment.log_metric(\"val_psnr\", psnr, step=val_step)\n","            if epoch % 1  == 0 and i == 0:\n","                # experiment.log_image(tensor_batch_to_pil(lr_images), name=f\"LR_image\", step=epoch)\n","                # experiment.log_image(tensor_batch_to_pil(hr_images), name=f\"HR_image\", step=epoch)\n","                # experiment.log_image(tensor_batch_to_pil(output_sr), name=f\"ISR output\", step=epoch)\n","                # experiment.log_image(tensor_batch_to_pil(outputs), name=f\"IQE output\", step=epoch)\n","                experiment.log_image(concat_triplet_batch(lr_images, output_sr, outputs, hr_images), name=\"Comparison\", step=epoch)\n","            val_step += 1\n","            \n","    val_psnr_epoch = epoch_val_psnr / len(valid_loader)\n","    val_loss_epoch = epoch_val_loss / len(valid_loader)\n","    experiment.log_metrics({'avg_train_loss':avg_epoch_loss, 'avg_val_loss':val_loss_epoch}, step=epoch)\n","    experiment.log_metrics({'avg_train_psnr':avg_epoch_psnr, 'avg_val_psnr':val_psnr_epoch}, step=epoch)\n","\n","    # Save best model\n","    \n","    if epoch % 10 == 0:\n","        save_checkpoint(iqe, optim_iqe, scheduler, epoch, train_step, val_step, best_loss, path=f\"outputs/path/iqe_{epoch}.pth\")\n","        save_checkpoint(isr, optim_iqe, scheduler, epoch, train_step, val_step, best_loss, path=f\"outputs/path/isr_{epoch}.pth\")\n","    save_checkpoint(iqe, optim_iqe, scheduler, epoch, train_step, val_step, best_loss, path=f\"outputs/checkpoint_iqe.pth\")\n","    save_checkpoint(isr, optim_iqe, scheduler, epoch, train_step, val_step, best_loss, path=f\"outputs/checkpoint_isr.pth\")\n","        \n","    print(f\"Epoch [{epoch+1}/{num_epochs}] completed: training loss: {avg_epoch_loss:.6f}, validation loss: {val_loss_epoch:.6f}, Training PSNR: {avg_epoch_psnr:.2f}, Validation PSNR: {val_psnr_epoch:.2f},\")\n","    log_file.write(f\"Epoch {epoch+1}:  training loss: {avg_epoch_loss:.6f}, validation loss: {val_loss_epoch:.6f}, Training PSNR: {avg_epoch_psnr:.2f}, Validation PSNR: {val_psnr_epoch:.2f}\\n\")\n","    if val_loss_epoch < best_loss:\n","        best_loss = val_loss_epoch\n","        save_checkpoint(iqe, optim_iqe, scheduler, epoch, train_step, val_step, best_loss, path=f\"outputs/weight/best_iqe_{quality}.pth\")\n","        save_checkpoint(isr, optim_iqe, scheduler, epoch, train_step, val_step, best_loss, path=f\"outputs/weight/best_isr_{quality}.pth\")\n","\n","        print(f\"Saved model with Val loss {best_loss:.4f}\")\n","        log_file.write(f\"Saved model with Val loss {best_loss:.4f}\\n\")\n","    log_file.flush()\n","    if elapsed_time >= max_training_time:\n","            print(\"Training stopped due to time limit.\")\n","            save_checkpoint(iqe, optim_iqe, scheduler, epoch, train_step, val_step, best_loss, path=\"outputs/checkpoint_iqe.pth\")\n","            save_checkpoint(isr, optim_iqe, scheduler, epoch, train_step, val_step, best_loss, path=\"outputs/checkpoint_isr.pth\")\n","            break\n","experiment.end()\n"]},{"cell_type":"markdown","metadata":{},"source":["# 5. Testing"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"execution_failed":"2025-08-12T09:23:54.077Z"},"trusted":true},"outputs":[],"source":["def load_weight(model, path=\"checkpoint.pth\"):\n","    if os.path.isfile(path):\n","        checkpoint = torch.load(path)\n","        model.load_state_dict(checkpoint['model_state_dict'])\n","        \n","    else:\n","        print(f\"No checkpoint found at {path}\")\n","        return 0, 0, float('-inf')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"execution_failed":"2025-08-12T09:23:54.077Z"},"trusted":true},"outputs":[],"source":["# load_check(f'outputs/best_esr_sobel_{quality}.pth', map_location=device))\n","load_weight(iqe, path=f'outputs/best_iqe_{quality}.pth')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":286056,"sourceId":588358,"sourceType":"datasetVersion"},{"datasetId":5401947,"sourceId":8972691,"sourceType":"datasetVersion"},{"datasetId":5407701,"sourceId":8980494,"sourceType":"datasetVersion"},{"datasetId":6085443,"sourceId":9905374,"sourceType":"datasetVersion"},{"datasetId":6494984,"sourceId":10489998,"sourceType":"datasetVersion"},{"datasetId":7923603,"sourceId":12593443,"sourceType":"datasetVersion"},{"datasetId":7972076,"sourceId":12716631,"sourceType":"datasetVersion"},{"datasetId":7976177,"sourceId":12749714,"sourceType":"datasetVersion"},{"datasetId":6793627,"sourceId":12749840,"sourceType":"datasetVersion"},{"modelId":164201,"modelInstanceId":141615,"sourceId":491881,"sourceType":"modelInstanceVersion"}],"dockerImageVersionId":30840,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.20"}},"nbformat":4,"nbformat_minor":4}
